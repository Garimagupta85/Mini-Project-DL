{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06276a29",
   "metadata": {},
   "source": [
    "Define dataset for cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import pickle\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        super().__init__()\n",
    "        # get all files in dataset folder, different files for train and test mode\n",
    "        if train:\n",
    "            files = sorted(glob.glob(\"./cifar-10-batches-py/data_*\"))\n",
    "        else:\n",
    "            files = glob.glob(\"./cifar-10-batches-py/test_*\")\n",
    "        self.train = train\n",
    "        data = []\n",
    "        label = []\n",
    "        # load files\n",
    "        for file in files:\n",
    "            with open(file, 'rb') as fo:\n",
    "                dic = pickle.load(fo, encoding='latin1')\n",
    "                data.append(dic['data'])\n",
    "                label.append(dic['labels'])\n",
    "        self.data = np.concatenate(data)\n",
    "        self.label = np.concatenate(label)\n",
    "        # specify preprocess operation for different mode\n",
    "        if train:\n",
    "            self.transform = A.Compose([\n",
    "                A.Cutout(),\n",
    "                A.PadIfNeeded(36, 36),\n",
    "                A.RandomCrop(32, 32),\n",
    "                A.HorizontalFlip(),\n",
    "                A.RandomRotate90(),\n",
    "                A.ChannelShuffle(),\n",
    "                A.ISONoise(),\n",
    "                A.RandomBrightnessContrast(),\n",
    "                A.ColorJitter(),\n",
    "                A.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = A.Compose([\n",
    "                A.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get image with specified index and perform related process defined in initial part\n",
    "        x = self.data[index]\n",
    "        y = self.label[index]\n",
    "        x = np.reshape(x, (3, 32, 32))\n",
    "        x = np.transpose(x, (1, 2, 0))\n",
    "        x = self.transform(image=x)['image']\n",
    "        x = np.transpose(x, (2, 0, 1))\n",
    "        return {\"x\": x, \"y\": y}\n",
    "\n",
    "    def __len__(self):\n",
    "        # return dataset length\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a70b3",
   "metadata": {},
   "source": [
    "Define neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# define residual block ( equation in report)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# define a resnet with 3 residual blocks and 2 Fully connected layer\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 32\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU())\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer0 = self._make_layer(32, 2, stride=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=1)\n",
    "        # self.layer3 = self._make_layer(512, 2, stride=2)\n",
    "        self.fc1 = nn.Linear(32768, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = [ResidualBlock(self.inplanes, planes, stride, downsample)]\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(ResidualBlock(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        # x = self.layer3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2762c",
   "metadata": {},
   "source": [
    "Define training and testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "def train():\n",
    "    # specify hyper-parameters here\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    batch_size = 128\n",
    "    lr = 1e-3\n",
    "    max_epoch = 200\n",
    "    eval_per_epoch = 2\n",
    "    # prepare two dataloaders\n",
    "    train_dataset = MyDataset(train=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "    test_dataset = MyDataset(train=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n",
    "    # initial network model and output to txt for network architecture\n",
    "    model = ResNet().to(device)\n",
    "    txt = str(summary(model, (3, 32, 32)))\n",
    "    text_file = open(\"model.txt\", \"w\")\n",
    "    text_file.write(txt)\n",
    "    text_file.close()\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    # use tensorboard to output collected data\n",
    "    logger = SummaryWriter()\n",
    "    global_step = 0\n",
    "    high_acc = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        model.train()\n",
    "        print(\"epoch:{}\".format(epoch))\n",
    "        for data in tqdm(train_loader):\n",
    "            # get data from dataloader\n",
    "            x = data['x'].to(device)\n",
    "            y = data[\"y\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # forward computing\n",
    "            pred = model(x)\n",
    "            # compute loss\n",
    "            loss = crit(pred, y)\n",
    "\n",
    "            global_step += 1\n",
    "            # record data\n",
    "            logger.add_scalar(\"loss\", loss.item(), global_step=global_step)\n",
    "            # do optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # do evaluation\n",
    "        if epoch % eval_per_epoch == 0:\n",
    "            print(\"eval\")\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                acc_list = []\n",
    "                for data in tqdm(test_loader):\n",
    "                    x = data['x'].to(device)\n",
    "                    y = data[\"y\"].to(device)\n",
    "                    pred = model(x)\n",
    "                    pred = torch.argmax(pred, dim=-1)\n",
    "                    acc = sum(pred == y) / len(pred)\n",
    "                    acc_list.append(acc.item())\n",
    "                acc = np.average(acc_list)\n",
    "                if acc > high_acc:\n",
    "                    high_acc = acc\n",
    "                    # save model if it's better than before\n",
    "                    torch.save(model, \"./model{}.pth\".format(high_acc))\n",
    "                logger.add_scalar(\"acc\", acc, epoch//eval_per_epoch)\n",
    "\n",
    "                print(\"accuracy:{}\".format(acc))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
