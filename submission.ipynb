{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ee83389f-a9b3-4864-a82d-e657fcdfccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/Mini-Project-DL\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51d931f3-2a00-4d16-822c-65dcca2492a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAResnet.ipynb  checkpoint\t\t  data\t      submission.ipynb\n",
      "README.md\t  cifar10_resnet18.ipynb  resnet.png\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15c317c6-2f13-484c-990d-0e785c7ff542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d473436e-81e6-43e0-a927-828bcdb6ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.13.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7ace70f8-a75d-47b4-bb0b-3ad2def6fd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: torch==1.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.5.1)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.38.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ab4a5f4c-8c99-4d39-a042-781a254d4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "45a66186-de75-4999-bd6c-44495ae9bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ed650fde-34c5-4b22-9dda-8980b42bf29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8c12b5c0-fa20-4234-883c-3d95f6c94ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "#_, term_width = os.popen('stty size', 'r').read().split()\n",
    "#term_width = int(term_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e61711b0-b777-4a4b-ae45-7122cdedebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "47534613-4523-4906-b70d-dc4358fbd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import progress_bar\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0be2910c-4a57-4dc3-8a92-8f27eb0a7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "70a8e21e-f374-4e19-a2a1-6b6fc732bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9fdb57ad-a400-47b1-b36d-583b1c447086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e3338aad-e23d-41a5-b983-54216f8e5635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1f911a57-de25-4e39-8a34-b1c5c1872997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomCrop(size=(32, 32), padding=4)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
       "           )"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cc41d0d0-af5c-46a3-b94a-053234cd9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(trainset) * VALID_RATIO)\n",
    "n_valid_examples = len(trainset) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(trainset, \n",
    "                                           [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8b1b400f-6419-459f-a53b-162b808ed6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7ff5e00cce80>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "14a917b4-94a4-46c6-af04-348e499d94e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7ff5e00ccc40>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ac0c4b4-b0ae-496a-81eb-81c68fd3e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a00cfce4-75c7-456e-a2f8-4ca097e2919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3906e02d-7556-499f-a57e-b524a5e22c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4b1af921-5eed-4670-8a9c-4cc3b79d5b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "24e9ac75-8935-479c-865d-cea4b6c80989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6ca8cdba-ad41-41af-9fb6-d44acc55ec3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
       "           )"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "85925983-5638-4fdf-afb7-ac458dd1b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "afec1542-188b-4404-b100-3a165a77187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "405399b9-f69e-4347-9b8d-20eb392cbebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        \"\"\"\n",
    "        in_planes: C_in for conv1 and Sequential.Conv2d\n",
    "        planes: F_i\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks,  num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 32\n",
    "        \"\"\"\n",
    "        in_planes: C_out of layer1\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "            \"\"\"\n",
    "            in_planes becomes the output of the current layer\n",
    "            \"\"\"\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4) # to be understood\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "77265181-9721-4b74-bf4a-b877d9ea1daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model..')\n",
    "net = ResNet18()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fa466e14-a159-4648-b890-00890d0ddf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b2fee59c-356e-4823-9f55-1730dc72958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            864\n",
      "├─BatchNorm2d: 1-2                       64\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─BasicBlock: 2-1                   --\n",
      "|    |    └─Conv2d: 3-1                  9,216\n",
      "|    |    └─BatchNorm2d: 3-2             64\n",
      "|    |    └─Conv2d: 3-3                  9,216\n",
      "|    |    └─BatchNorm2d: 3-4             64\n",
      "|    |    └─Sequential: 3-5              --\n",
      "|    └─BasicBlock: 2-2                   --\n",
      "|    |    └─Conv2d: 3-6                  9,216\n",
      "|    |    └─BatchNorm2d: 3-7             64\n",
      "|    |    └─Conv2d: 3-8                  9,216\n",
      "|    |    └─BatchNorm2d: 3-9             64\n",
      "|    |    └─Sequential: 3-10             --\n",
      "├─Sequential: 1-4                        --\n",
      "|    └─BasicBlock: 2-3                   --\n",
      "|    |    └─Conv2d: 3-11                 18,432\n",
      "|    |    └─BatchNorm2d: 3-12            128\n",
      "|    |    └─Conv2d: 3-13                 36,864\n",
      "|    |    └─BatchNorm2d: 3-14            128\n",
      "|    |    └─Sequential: 3-15             2,176\n",
      "|    └─BasicBlock: 2-4                   --\n",
      "|    |    └─Conv2d: 3-16                 36,864\n",
      "|    |    └─BatchNorm2d: 3-17            128\n",
      "|    |    └─Conv2d: 3-18                 36,864\n",
      "|    |    └─BatchNorm2d: 3-19            128\n",
      "|    |    └─Sequential: 3-20             --\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─BasicBlock: 2-5                   --\n",
      "|    |    └─Conv2d: 3-21                 73,728\n",
      "|    |    └─BatchNorm2d: 3-22            256\n",
      "|    |    └─Conv2d: 3-23                 147,456\n",
      "|    |    └─BatchNorm2d: 3-24            256\n",
      "|    |    └─Sequential: 3-25             8,448\n",
      "|    └─BasicBlock: 2-6                   --\n",
      "|    |    └─Conv2d: 3-26                 147,456\n",
      "|    |    └─BatchNorm2d: 3-27            256\n",
      "|    |    └─Conv2d: 3-28                 147,456\n",
      "|    |    └─BatchNorm2d: 3-29            256\n",
      "|    |    └─Sequential: 3-30             --\n",
      "├─Sequential: 1-6                        --\n",
      "|    └─BasicBlock: 2-7                   --\n",
      "|    |    └─Conv2d: 3-31                 294,912\n",
      "|    |    └─BatchNorm2d: 3-32            512\n",
      "|    |    └─Conv2d: 3-33                 589,824\n",
      "|    |    └─BatchNorm2d: 3-34            512\n",
      "|    |    └─Sequential: 3-35             33,280\n",
      "|    └─BasicBlock: 2-8                   --\n",
      "|    |    └─Conv2d: 3-36                 589,824\n",
      "|    |    └─BatchNorm2d: 3-37            512\n",
      "|    |    └─Conv2d: 3-38                 589,824\n",
      "|    |    └─BatchNorm2d: 3-39            512\n",
      "|    |    └─Sequential: 3-40             --\n",
      "├─Linear: 1-7                            2,570\n",
      "=================================================================\n",
      "Total params: 2,797,610\n",
      "Trainable params: 2,797,610\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Conv2d: 1-1                            864\n",
       "├─BatchNorm2d: 1-2                       64\n",
       "├─Sequential: 1-3                        --\n",
       "|    └─BasicBlock: 2-1                   --\n",
       "|    |    └─Conv2d: 3-1                  9,216\n",
       "|    |    └─BatchNorm2d: 3-2             64\n",
       "|    |    └─Conv2d: 3-3                  9,216\n",
       "|    |    └─BatchNorm2d: 3-4             64\n",
       "|    |    └─Sequential: 3-5              --\n",
       "|    └─BasicBlock: 2-2                   --\n",
       "|    |    └─Conv2d: 3-6                  9,216\n",
       "|    |    └─BatchNorm2d: 3-7             64\n",
       "|    |    └─Conv2d: 3-8                  9,216\n",
       "|    |    └─BatchNorm2d: 3-9             64\n",
       "|    |    └─Sequential: 3-10             --\n",
       "├─Sequential: 1-4                        --\n",
       "|    └─BasicBlock: 2-3                   --\n",
       "|    |    └─Conv2d: 3-11                 18,432\n",
       "|    |    └─BatchNorm2d: 3-12            128\n",
       "|    |    └─Conv2d: 3-13                 36,864\n",
       "|    |    └─BatchNorm2d: 3-14            128\n",
       "|    |    └─Sequential: 3-15             2,176\n",
       "|    └─BasicBlock: 2-4                   --\n",
       "|    |    └─Conv2d: 3-16                 36,864\n",
       "|    |    └─BatchNorm2d: 3-17            128\n",
       "|    |    └─Conv2d: 3-18                 36,864\n",
       "|    |    └─BatchNorm2d: 3-19            128\n",
       "|    |    └─Sequential: 3-20             --\n",
       "├─Sequential: 1-5                        --\n",
       "|    └─BasicBlock: 2-5                   --\n",
       "|    |    └─Conv2d: 3-21                 73,728\n",
       "|    |    └─BatchNorm2d: 3-22            256\n",
       "|    |    └─Conv2d: 3-23                 147,456\n",
       "|    |    └─BatchNorm2d: 3-24            256\n",
       "|    |    └─Sequential: 3-25             8,448\n",
       "|    └─BasicBlock: 2-6                   --\n",
       "|    |    └─Conv2d: 3-26                 147,456\n",
       "|    |    └─BatchNorm2d: 3-27            256\n",
       "|    |    └─Conv2d: 3-28                 147,456\n",
       "|    |    └─BatchNorm2d: 3-29            256\n",
       "|    |    └─Sequential: 3-30             --\n",
       "├─Sequential: 1-6                        --\n",
       "|    └─BasicBlock: 2-7                   --\n",
       "|    |    └─Conv2d: 3-31                 294,912\n",
       "|    |    └─BatchNorm2d: 3-32            512\n",
       "|    |    └─Conv2d: 3-33                 589,824\n",
       "|    |    └─BatchNorm2d: 3-34            512\n",
       "|    |    └─Sequential: 3-35             33,280\n",
       "|    └─BasicBlock: 2-8                   --\n",
       "|    |    └─Conv2d: 3-36                 589,824\n",
       "|    |    └─BatchNorm2d: 3-37            512\n",
       "|    |    └─Conv2d: 3-38                 589,824\n",
       "|    |    └─BatchNorm2d: 3-39            512\n",
       "|    |    └─Sequential: 3-40             --\n",
       "├─Linear: 1-7                            2,570\n",
       "=================================================================\n",
       "Total params: 2,797,610\n",
       "Trainable params: 2,797,610\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(net, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7f0f1fa3-ccf1-4d27-9b5b-33e1f979f9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "11b9ddac-9903-4b60-bc43-c7575505c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5654e62c-fdca-4005-87d5-c626b83a5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "if resume == True:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e666fc97-7784-4cdd-ac4d-ada985110509",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001,\n",
    "                      #momentum=0.9, \n",
    "                       weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5c447abe-7a21-48c9-97ed-275e5764c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "67dd76ba-2d61-4893-b3dc-49ae62d09e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "15511c65-995d-442b-9010-09c82ac28c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "20fb231a-c978-4bfd-a4e3-be6cba4a8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    steps = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        steps = steps+1\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        #progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "        #             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        if steps%87==0:\n",
    "            print(f\"Epoch:{epoch} --Progress(%):{batch_idx/len(trainloader)*100.:.2f}-- Loss:{train_loss/(batch_idx+1):.2f} -- Acc:{100.*correct/total:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e401698b-798c-42b0-99e3-438ddcd89b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            #progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    print(f\"Epoch:{epoch} --Val Loss:{val_loss/(batch_idx+1):.2f} -- Acc:{100.*correct/total:.2f}\")\n",
    "            \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving the best model.')\n",
    "        #state = {\n",
    "        #    'net': net.state_dict(),\n",
    "        #    'acc': acc,\n",
    "        #    'epoch': epoch,\n",
    "        #}\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        #torch.save(state, './checkpoint/ckpt.pth')\n",
    "        \n",
    "        torch.save(net.state_dict(), './checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b5cfb159-d153-41f3-b0e8-386264c8c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    print(\"***** Begin testing *****\")\n",
    "    net.load_state_dict(torch.load('./checkpoint/ckpt.pth'))\n",
    "    net.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            #progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    print(f\"Epoch:{epoch} --Test Loss:{test_loss/(batch_idx+1):.2f} -- Acc:{100.*correct/total:.2f}\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9150bd92-d2ea-4a25-b6cb-ea7a312e2f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Epoch:0 --Progress(%):24.43-- Loss:1.86 -- Acc:30.52\n",
      "Epoch:0 --Progress(%):49.15-- Loss:1.71 -- Acc:36.64\n",
      "Epoch:0 --Progress(%):73.86-- Loss:1.62 -- Acc:40.28\n",
      "Epoch:0 --Progress(%):98.58-- Loss:1.55 -- Acc:42.94\n",
      "Epoch:0 --Val Loss:1.36 -- Acc:50.96\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 1\n",
      "Epoch:1 --Progress(%):24.43-- Loss:1.27 -- Acc:54.09\n",
      "Epoch:1 --Progress(%):49.15-- Loss:1.25 -- Acc:55.08\n",
      "Epoch:1 --Progress(%):73.86-- Loss:1.22 -- Acc:55.95\n",
      "Epoch:1 --Progress(%):98.58-- Loss:1.20 -- Acc:56.87\n",
      "Epoch:1 --Val Loss:1.10 -- Acc:60.46\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 2\n",
      "Epoch:2 --Progress(%):24.43-- Loss:1.07 -- Acc:61.88\n",
      "Epoch:2 --Progress(%):49.15-- Loss:1.05 -- Acc:62.75\n",
      "Epoch:2 --Progress(%):73.86-- Loss:1.04 -- Acc:63.16\n",
      "Epoch:2 --Progress(%):98.58-- Loss:1.02 -- Acc:63.79\n",
      "Epoch:2 --Val Loss:1.04 -- Acc:63.30\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 3\n",
      "Epoch:3 --Progress(%):24.43-- Loss:0.94 -- Acc:66.50\n",
      "Epoch:3 --Progress(%):49.15-- Loss:0.93 -- Acc:67.10\n",
      "Epoch:3 --Progress(%):73.86-- Loss:0.91 -- Acc:67.74\n",
      "Epoch:3 --Progress(%):98.58-- Loss:0.90 -- Acc:68.03\n",
      "Epoch:3 --Val Loss:1.00 -- Acc:64.72\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 4\n",
      "Epoch:4 --Progress(%):24.43-- Loss:0.85 -- Acc:69.59\n",
      "Epoch:4 --Progress(%):49.15-- Loss:0.84 -- Acc:70.33\n",
      "Epoch:4 --Progress(%):73.86-- Loss:0.83 -- Acc:70.73\n",
      "Epoch:4 --Progress(%):98.58-- Loss:0.82 -- Acc:71.08\n",
      "Epoch:4 --Val Loss:0.82 -- Acc:70.12\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 5\n",
      "Epoch:5 --Progress(%):24.43-- Loss:0.76 -- Acc:73.32\n",
      "Epoch:5 --Progress(%):49.15-- Loss:0.75 -- Acc:73.64\n",
      "Epoch:5 --Progress(%):73.86-- Loss:0.75 -- Acc:73.82\n",
      "Epoch:5 --Progress(%):98.58-- Loss:0.74 -- Acc:74.23\n",
      "Epoch:5 --Val Loss:0.74 -- Acc:73.70\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 6\n",
      "Epoch:6 --Progress(%):24.43-- Loss:0.68 -- Acc:76.09\n",
      "Epoch:6 --Progress(%):49.15-- Loss:0.68 -- Acc:76.12\n",
      "Epoch:6 --Progress(%):73.86-- Loss:0.68 -- Acc:76.29\n",
      "Epoch:6 --Progress(%):98.58-- Loss:0.67 -- Acc:76.36\n",
      "Epoch:6 --Val Loss:0.70 -- Acc:75.04\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 7\n",
      "Epoch:7 --Progress(%):24.43-- Loss:0.62 -- Acc:78.59\n",
      "Epoch:7 --Progress(%):49.15-- Loss:0.62 -- Acc:78.20\n",
      "Epoch:7 --Progress(%):73.86-- Loss:0.62 -- Acc:78.32\n",
      "Epoch:7 --Progress(%):98.58-- Loss:0.62 -- Acc:78.31\n",
      "Epoch:7 --Val Loss:0.69 -- Acc:75.54\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 8\n",
      "Epoch:8 --Progress(%):24.43-- Loss:0.58 -- Acc:79.80\n",
      "Epoch:8 --Progress(%):49.15-- Loss:0.58 -- Acc:79.91\n",
      "Epoch:8 --Progress(%):73.86-- Loss:0.58 -- Acc:79.86\n",
      "Epoch:8 --Progress(%):98.58-- Loss:0.58 -- Acc:79.98\n",
      "Epoch:8 --Val Loss:0.65 -- Acc:77.28\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 9\n",
      "Epoch:9 --Progress(%):24.43-- Loss:0.55 -- Acc:80.65\n",
      "Epoch:9 --Progress(%):49.15-- Loss:0.55 -- Acc:81.11\n",
      "Epoch:9 --Progress(%):73.86-- Loss:0.54 -- Acc:81.29\n",
      "Epoch:9 --Progress(%):98.58-- Loss:0.54 -- Acc:81.10\n",
      "Epoch:9 --Val Loss:0.62 -- Acc:79.44\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 10\n",
      "Epoch:10 --Progress(%):24.43-- Loss:0.51 -- Acc:82.45\n",
      "Epoch:10 --Progress(%):49.15-- Loss:0.51 -- Acc:82.33\n",
      "Epoch:10 --Progress(%):73.86-- Loss:0.51 -- Acc:82.29\n",
      "Epoch:10 --Progress(%):98.58-- Loss:0.51 -- Acc:82.39\n",
      "Epoch:10 --Val Loss:0.59 -- Acc:79.26\n",
      "\n",
      "Epoch: 11\n",
      "Epoch:11 --Progress(%):24.43-- Loss:0.47 -- Acc:83.82\n",
      "Epoch:11 --Progress(%):49.15-- Loss:0.47 -- Acc:83.78\n",
      "Epoch:11 --Progress(%):73.86-- Loss:0.48 -- Acc:83.36\n",
      "Epoch:11 --Progress(%):98.58-- Loss:0.48 -- Acc:83.18\n",
      "Epoch:11 --Val Loss:0.59 -- Acc:79.70\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 12\n",
      "Epoch:12 --Progress(%):24.43-- Loss:0.45 -- Acc:84.72\n",
      "Epoch:12 --Progress(%):49.15-- Loss:0.46 -- Acc:84.11\n",
      "Epoch:12 --Progress(%):73.86-- Loss:0.46 -- Acc:84.17\n",
      "Epoch:12 --Progress(%):98.58-- Loss:0.46 -- Acc:84.10\n",
      "Epoch:12 --Val Loss:0.62 -- Acc:78.54\n",
      "\n",
      "Epoch: 13\n",
      "Epoch:13 --Progress(%):24.43-- Loss:0.43 -- Acc:85.28\n",
      "Epoch:13 --Progress(%):49.15-- Loss:0.44 -- Acc:85.12\n",
      "Epoch:13 --Progress(%):73.86-- Loss:0.44 -- Acc:84.96\n",
      "Epoch:13 --Progress(%):98.58-- Loss:0.44 -- Acc:84.93\n",
      "Epoch:13 --Val Loss:0.57 -- Acc:80.88\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 14\n",
      "Epoch:14 --Progress(%):24.43-- Loss:0.42 -- Acc:85.70\n",
      "Epoch:14 --Progress(%):49.15-- Loss:0.42 -- Acc:85.50\n",
      "Epoch:14 --Progress(%):73.86-- Loss:0.42 -- Acc:85.60\n",
      "Epoch:14 --Progress(%):98.58-- Loss:0.42 -- Acc:85.52\n",
      "Epoch:14 --Val Loss:0.57 -- Acc:80.08\n",
      "\n",
      "Epoch: 15\n",
      "Epoch:15 --Progress(%):24.43-- Loss:0.39 -- Acc:86.24\n",
      "Epoch:15 --Progress(%):49.15-- Loss:0.39 -- Acc:86.39\n",
      "Epoch:15 --Progress(%):73.86-- Loss:0.39 -- Acc:86.25\n",
      "Epoch:15 --Progress(%):98.58-- Loss:0.39 -- Acc:86.27\n",
      "Epoch:15 --Val Loss:0.56 -- Acc:81.30\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 16\n",
      "Epoch:16 --Progress(%):24.43-- Loss:0.36 -- Acc:87.63\n",
      "Epoch:16 --Progress(%):49.15-- Loss:0.37 -- Acc:86.88\n",
      "Epoch:16 --Progress(%):73.86-- Loss:0.37 -- Acc:86.98\n",
      "Epoch:16 --Progress(%):98.58-- Loss:0.38 -- Acc:86.95\n",
      "Epoch:16 --Val Loss:0.53 -- Acc:81.98\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 17\n",
      "Epoch:17 --Progress(%):24.43-- Loss:0.36 -- Acc:87.72\n",
      "Epoch:17 --Progress(%):49.15-- Loss:0.36 -- Acc:87.82\n",
      "Epoch:17 --Progress(%):73.86-- Loss:0.36 -- Acc:87.81\n",
      "Epoch:17 --Progress(%):98.58-- Loss:0.36 -- Acc:87.75\n",
      "Epoch:17 --Val Loss:0.49 -- Acc:83.18\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 18\n",
      "Epoch:18 --Progress(%):24.43-- Loss:0.33 -- Acc:88.30\n",
      "Epoch:18 --Progress(%):49.15-- Loss:0.34 -- Acc:88.10\n",
      "Epoch:18 --Progress(%):73.86-- Loss:0.35 -- Acc:87.96\n",
      "Epoch:18 --Progress(%):98.58-- Loss:0.35 -- Acc:88.02\n",
      "Epoch:18 --Val Loss:0.57 -- Acc:81.38\n",
      "\n",
      "Epoch: 19\n",
      "Epoch:19 --Progress(%):24.43-- Loss:0.33 -- Acc:88.45\n",
      "Epoch:19 --Progress(%):49.15-- Loss:0.33 -- Acc:88.30\n",
      "Epoch:19 --Progress(%):73.86-- Loss:0.34 -- Acc:88.42\n",
      "Epoch:19 --Progress(%):98.58-- Loss:0.33 -- Acc:88.49\n",
      "Epoch:19 --Val Loss:0.48 -- Acc:84.04\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 20\n",
      "Epoch:20 --Progress(%):24.43-- Loss:0.31 -- Acc:89.18\n",
      "Epoch:20 --Progress(%):49.15-- Loss:0.31 -- Acc:89.25\n",
      "Epoch:20 --Progress(%):73.86-- Loss:0.31 -- Acc:89.10\n",
      "Epoch:20 --Progress(%):98.58-- Loss:0.31 -- Acc:89.11\n",
      "Epoch:20 --Val Loss:0.50 -- Acc:82.78\n",
      "\n",
      "Epoch: 21\n",
      "Epoch:21 --Progress(%):24.43-- Loss:0.29 -- Acc:90.01\n",
      "Epoch:21 --Progress(%):49.15-- Loss:0.30 -- Acc:89.59\n",
      "Epoch:21 --Progress(%):73.86-- Loss:0.30 -- Acc:89.37\n",
      "Epoch:21 --Progress(%):98.58-- Loss:0.31 -- Acc:89.30\n",
      "Epoch:21 --Val Loss:0.47 -- Acc:83.74\n",
      "\n",
      "Epoch: 22\n",
      "Epoch:22 --Progress(%):24.43-- Loss:0.29 -- Acc:90.19\n",
      "Epoch:22 --Progress(%):49.15-- Loss:0.29 -- Acc:89.99\n",
      "Epoch:22 --Progress(%):73.86-- Loss:0.29 -- Acc:89.95\n",
      "Epoch:22 --Progress(%):98.58-- Loss:0.29 -- Acc:89.90\n",
      "Epoch:22 --Val Loss:0.44 -- Acc:84.70\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 23\n",
      "Epoch:23 --Progress(%):24.43-- Loss:0.26 -- Acc:90.78\n",
      "Epoch:23 --Progress(%):49.15-- Loss:0.27 -- Acc:90.60\n",
      "Epoch:23 --Progress(%):73.86-- Loss:0.27 -- Acc:90.70\n",
      "Epoch:23 --Progress(%):98.58-- Loss:0.28 -- Acc:90.39\n",
      "Epoch:23 --Val Loss:0.49 -- Acc:83.62\n",
      "\n",
      "Epoch: 24\n",
      "Epoch:24 --Progress(%):24.43-- Loss:0.26 -- Acc:90.85\n",
      "Epoch:24 --Progress(%):49.15-- Loss:0.26 -- Acc:90.76\n",
      "Epoch:24 --Progress(%):73.86-- Loss:0.27 -- Acc:90.70\n",
      "Epoch:24 --Progress(%):98.58-- Loss:0.27 -- Acc:90.64\n",
      "Epoch:24 --Val Loss:0.50 -- Acc:84.44\n",
      "\n",
      "Epoch: 25\n",
      "Epoch:25 --Progress(%):24.43-- Loss:0.24 -- Acc:91.67\n",
      "Epoch:25 --Progress(%):49.15-- Loss:0.25 -- Acc:91.34\n",
      "Epoch:25 --Progress(%):73.86-- Loss:0.26 -- Acc:91.03\n",
      "Epoch:25 --Progress(%):98.58-- Loss:0.26 -- Acc:91.03\n",
      "Epoch:25 --Val Loss:0.43 -- Acc:85.82\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 26\n",
      "Epoch:26 --Progress(%):24.43-- Loss:0.25 -- Acc:91.41\n",
      "Epoch:26 --Progress(%):49.15-- Loss:0.25 -- Acc:91.45\n",
      "Epoch:26 --Progress(%):73.86-- Loss:0.25 -- Acc:91.33\n",
      "Epoch:26 --Progress(%):98.58-- Loss:0.25 -- Acc:91.18\n",
      "Epoch:26 --Val Loss:0.45 -- Acc:85.10\n",
      "\n",
      "Epoch: 27\n",
      "Epoch:27 --Progress(%):24.43-- Loss:0.24 -- Acc:91.85\n",
      "Epoch:27 --Progress(%):49.15-- Loss:0.23 -- Acc:91.84\n",
      "Epoch:27 --Progress(%):73.86-- Loss:0.24 -- Acc:91.62\n",
      "Epoch:27 --Progress(%):98.58-- Loss:0.24 -- Acc:91.57\n",
      "Epoch:27 --Val Loss:0.46 -- Acc:85.12\n",
      "\n",
      "Epoch: 28\n",
      "Epoch:28 --Progress(%):24.43-- Loss:0.22 -- Acc:92.57\n",
      "Epoch:28 --Progress(%):49.15-- Loss:0.23 -- Acc:92.31\n",
      "Epoch:28 --Progress(%):73.86-- Loss:0.23 -- Acc:92.26\n",
      "Epoch:28 --Progress(%):98.58-- Loss:0.23 -- Acc:92.16\n",
      "Epoch:28 --Val Loss:0.45 -- Acc:85.28\n",
      "\n",
      "Epoch: 29\n",
      "Epoch:29 --Progress(%):24.43-- Loss:0.22 -- Acc:92.62\n",
      "Epoch:29 --Progress(%):49.15-- Loss:0.22 -- Acc:92.48\n",
      "Epoch:29 --Progress(%):73.86-- Loss:0.22 -- Acc:92.27\n",
      "Epoch:29 --Progress(%):98.58-- Loss:0.22 -- Acc:92.27\n",
      "Epoch:29 --Val Loss:0.46 -- Acc:85.94\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 30\n",
      "Epoch:30 --Progress(%):24.43-- Loss:0.21 -- Acc:92.71\n",
      "Epoch:30 --Progress(%):49.15-- Loss:0.21 -- Acc:92.66\n",
      "Epoch:30 --Progress(%):73.86-- Loss:0.22 -- Acc:92.57\n",
      "Epoch:30 --Progress(%):98.58-- Loss:0.22 -- Acc:92.57\n",
      "Epoch:30 --Val Loss:0.46 -- Acc:85.00\n",
      "\n",
      "Epoch: 31\n",
      "Epoch:31 --Progress(%):24.43-- Loss:0.20 -- Acc:93.00\n",
      "Epoch:31 --Progress(%):49.15-- Loss:0.20 -- Acc:93.14\n",
      "Epoch:31 --Progress(%):73.86-- Loss:0.20 -- Acc:92.93\n",
      "Epoch:31 --Progress(%):98.58-- Loss:0.20 -- Acc:92.79\n",
      "Epoch:31 --Val Loss:0.42 -- Acc:85.90\n",
      "\n",
      "Epoch: 32\n",
      "Epoch:32 --Progress(%):24.43-- Loss:0.19 -- Acc:93.74\n",
      "Epoch:32 --Progress(%):49.15-- Loss:0.20 -- Acc:93.31\n",
      "Epoch:32 --Progress(%):73.86-- Loss:0.20 -- Acc:93.21\n",
      "Epoch:32 --Progress(%):98.58-- Loss:0.20 -- Acc:93.11\n",
      "Epoch:32 --Val Loss:0.45 -- Acc:85.82\n",
      "\n",
      "Epoch: 33\n",
      "Epoch:33 --Progress(%):24.43-- Loss:0.18 -- Acc:94.06\n",
      "Epoch:33 --Progress(%):49.15-- Loss:0.19 -- Acc:93.75\n",
      "Epoch:33 --Progress(%):73.86-- Loss:0.19 -- Acc:93.68\n",
      "Epoch:33 --Progress(%):98.58-- Loss:0.19 -- Acc:93.61\n",
      "Epoch:33 --Val Loss:0.47 -- Acc:85.56\n",
      "\n",
      "Epoch: 34\n",
      "Epoch:34 --Progress(%):24.43-- Loss:0.18 -- Acc:93.64\n",
      "Epoch:34 --Progress(%):49.15-- Loss:0.18 -- Acc:93.66\n",
      "Epoch:34 --Progress(%):73.86-- Loss:0.18 -- Acc:93.69\n",
      "Epoch:34 --Progress(%):98.58-- Loss:0.19 -- Acc:93.58\n",
      "Epoch:34 --Val Loss:0.43 -- Acc:86.24\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 35\n",
      "Epoch:35 --Progress(%):24.43-- Loss:0.17 -- Acc:94.14\n",
      "Epoch:35 --Progress(%):49.15-- Loss:0.18 -- Acc:93.86\n",
      "Epoch:35 --Progress(%):73.86-- Loss:0.18 -- Acc:93.95\n",
      "Epoch:35 --Progress(%):98.58-- Loss:0.18 -- Acc:93.75\n",
      "Epoch:35 --Val Loss:0.46 -- Acc:85.58\n",
      "\n",
      "Epoch: 36\n",
      "Epoch:36 --Progress(%):24.43-- Loss:0.17 -- Acc:94.07\n",
      "Epoch:36 --Progress(%):49.15-- Loss:0.17 -- Acc:94.03\n",
      "Epoch:36 --Progress(%):73.86-- Loss:0.17 -- Acc:94.08\n",
      "Epoch:36 --Progress(%):98.58-- Loss:0.17 -- Acc:94.07\n",
      "Epoch:36 --Val Loss:0.46 -- Acc:85.42\n",
      "\n",
      "Epoch: 37\n",
      "Epoch:37 --Progress(%):24.43-- Loss:0.16 -- Acc:94.15\n",
      "Epoch:37 --Progress(%):49.15-- Loss:0.16 -- Acc:94.50\n",
      "Epoch:37 --Progress(%):73.86-- Loss:0.16 -- Acc:94.51\n",
      "Epoch:37 --Progress(%):98.58-- Loss:0.16 -- Acc:94.34\n",
      "Epoch:37 --Val Loss:0.42 -- Acc:86.66\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 38\n",
      "Epoch:38 --Progress(%):24.43-- Loss:0.14 -- Acc:95.18\n",
      "Epoch:38 --Progress(%):49.15-- Loss:0.15 -- Acc:94.83\n",
      "Epoch:38 --Progress(%):73.86-- Loss:0.15 -- Acc:94.71\n",
      "Epoch:38 --Progress(%):98.58-- Loss:0.16 -- Acc:94.59\n",
      "Epoch:38 --Val Loss:0.44 -- Acc:86.32\n",
      "\n",
      "Epoch: 39\n",
      "Epoch:39 --Progress(%):24.43-- Loss:0.15 -- Acc:94.97\n",
      "Epoch:39 --Progress(%):49.15-- Loss:0.15 -- Acc:94.85\n",
      "Epoch:39 --Progress(%):73.86-- Loss:0.16 -- Acc:94.70\n",
      "Epoch:39 --Progress(%):98.58-- Loss:0.16 -- Acc:94.64\n",
      "Epoch:39 --Val Loss:0.42 -- Acc:86.80\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 40\n",
      "Epoch:40 --Progress(%):24.43-- Loss:0.15 -- Acc:94.90\n",
      "Epoch:40 --Progress(%):49.15-- Loss:0.15 -- Acc:95.00\n",
      "Epoch:40 --Progress(%):73.86-- Loss:0.15 -- Acc:94.85\n",
      "Epoch:40 --Progress(%):98.58-- Loss:0.15 -- Acc:94.72\n",
      "Epoch:40 --Val Loss:0.46 -- Acc:86.02\n",
      "\n",
      "Epoch: 41\n",
      "Epoch:41 --Progress(%):24.43-- Loss:0.15 -- Acc:94.98\n",
      "Epoch:41 --Progress(%):49.15-- Loss:0.14 -- Acc:95.11\n",
      "Epoch:41 --Progress(%):73.86-- Loss:0.15 -- Acc:94.92\n",
      "Epoch:41 --Progress(%):98.58-- Loss:0.15 -- Acc:94.81\n",
      "Epoch:41 --Val Loss:0.42 -- Acc:86.88\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 42\n",
      "Epoch:42 --Progress(%):24.43-- Loss:0.13 -- Acc:95.59\n",
      "Epoch:42 --Progress(%):49.15-- Loss:0.13 -- Acc:95.43\n",
      "Epoch:42 --Progress(%):73.86-- Loss:0.14 -- Acc:95.33\n",
      "Epoch:42 --Progress(%):98.58-- Loss:0.14 -- Acc:95.22\n",
      "Epoch:42 --Val Loss:0.42 -- Acc:87.04\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 43\n",
      "Epoch:43 --Progress(%):24.43-- Loss:0.14 -- Acc:95.39\n",
      "Epoch:43 --Progress(%):49.15-- Loss:0.13 -- Acc:95.34\n",
      "Epoch:43 --Progress(%):73.86-- Loss:0.13 -- Acc:95.41\n",
      "Epoch:43 --Progress(%):98.58-- Loss:0.14 -- Acc:95.27\n",
      "Epoch:43 --Val Loss:0.42 -- Acc:87.34\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 44\n",
      "Epoch:44 --Progress(%):24.43-- Loss:0.12 -- Acc:95.96\n",
      "Epoch:44 --Progress(%):49.15-- Loss:0.12 -- Acc:95.89\n",
      "Epoch:44 --Progress(%):73.86-- Loss:0.13 -- Acc:95.71\n",
      "Epoch:44 --Progress(%):98.58-- Loss:0.13 -- Acc:95.75\n",
      "Epoch:44 --Val Loss:0.45 -- Acc:86.44\n",
      "\n",
      "Epoch: 45\n",
      "Epoch:45 --Progress(%):24.43-- Loss:0.12 -- Acc:95.78\n",
      "Epoch:45 --Progress(%):49.15-- Loss:0.13 -- Acc:95.78\n",
      "Epoch:45 --Progress(%):73.86-- Loss:0.13 -- Acc:95.71\n",
      "Epoch:45 --Progress(%):98.58-- Loss:0.13 -- Acc:95.68\n",
      "Epoch:45 --Val Loss:0.45 -- Acc:86.40\n",
      "\n",
      "Epoch: 46\n",
      "Epoch:46 --Progress(%):24.43-- Loss:0.12 -- Acc:95.95\n",
      "Epoch:46 --Progress(%):49.15-- Loss:0.12 -- Acc:95.88\n",
      "Epoch:46 --Progress(%):73.86-- Loss:0.12 -- Acc:95.83\n",
      "Epoch:46 --Progress(%):98.58-- Loss:0.12 -- Acc:95.88\n",
      "Epoch:46 --Val Loss:0.43 -- Acc:86.74\n",
      "\n",
      "Epoch: 47\n",
      "Epoch:47 --Progress(%):24.43-- Loss:0.12 -- Acc:96.06\n",
      "Epoch:47 --Progress(%):49.15-- Loss:0.12 -- Acc:96.06\n",
      "Epoch:47 --Progress(%):73.86-- Loss:0.12 -- Acc:95.99\n",
      "Epoch:47 --Progress(%):98.58-- Loss:0.12 -- Acc:95.88\n",
      "Epoch:47 --Val Loss:0.44 -- Acc:86.68\n",
      "\n",
      "Epoch: 48\n",
      "Epoch:48 --Progress(%):24.43-- Loss:0.10 -- Acc:96.51\n",
      "Epoch:48 --Progress(%):49.15-- Loss:0.11 -- Acc:96.27\n",
      "Epoch:48 --Progress(%):73.86-- Loss:0.11 -- Acc:96.23\n",
      "Epoch:48 --Progress(%):98.58-- Loss:0.11 -- Acc:96.10\n",
      "Epoch:48 --Val Loss:0.45 -- Acc:86.52\n",
      "\n",
      "Epoch: 49\n",
      "Epoch:49 --Progress(%):24.43-- Loss:0.11 -- Acc:96.35\n",
      "Epoch:49 --Progress(%):49.15-- Loss:0.11 -- Acc:96.19\n",
      "Epoch:49 --Progress(%):73.86-- Loss:0.11 -- Acc:96.25\n",
      "Epoch:49 --Progress(%):98.58-- Loss:0.11 -- Acc:96.19\n",
      "Epoch:49 --Val Loss:0.46 -- Acc:86.76\n",
      "\n",
      "Epoch: 50\n",
      "Epoch:50 --Progress(%):24.43-- Loss:0.10 -- Acc:96.36\n",
      "Epoch:50 --Progress(%):49.15-- Loss:0.11 -- Acc:96.19\n",
      "Epoch:50 --Progress(%):73.86-- Loss:0.11 -- Acc:96.17\n",
      "Epoch:50 --Progress(%):98.58-- Loss:0.11 -- Acc:96.16\n",
      "Epoch:50 --Val Loss:0.43 -- Acc:87.30\n",
      "\n",
      "Epoch: 51\n",
      "Epoch:51 --Progress(%):24.43-- Loss:0.10 -- Acc:96.85\n",
      "Epoch:51 --Progress(%):49.15-- Loss:0.10 -- Acc:96.72\n",
      "Epoch:51 --Progress(%):73.86-- Loss:0.10 -- Acc:96.50\n",
      "Epoch:51 --Progress(%):98.58-- Loss:0.11 -- Acc:96.37\n",
      "Epoch:51 --Val Loss:0.48 -- Acc:86.16\n",
      "\n",
      "Epoch: 52\n",
      "Epoch:52 --Progress(%):24.43-- Loss:0.09 -- Acc:96.79\n",
      "Epoch:52 --Progress(%):49.15-- Loss:0.09 -- Acc:96.78\n",
      "Epoch:52 --Progress(%):73.86-- Loss:0.10 -- Acc:96.60\n",
      "Epoch:52 --Progress(%):98.58-- Loss:0.10 -- Acc:96.53\n",
      "Epoch:52 --Val Loss:0.42 -- Acc:87.92\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 53\n",
      "Epoch:53 --Progress(%):24.43-- Loss:0.09 -- Acc:97.10\n",
      "Epoch:53 --Progress(%):49.15-- Loss:0.09 -- Acc:97.05\n",
      "Epoch:53 --Progress(%):73.86-- Loss:0.09 -- Acc:96.93\n",
      "Epoch:53 --Progress(%):98.58-- Loss:0.09 -- Acc:96.86\n",
      "Epoch:53 --Val Loss:0.45 -- Acc:87.46\n",
      "\n",
      "Epoch: 54\n",
      "Epoch:54 --Progress(%):24.43-- Loss:0.08 -- Acc:97.49\n",
      "Epoch:54 --Progress(%):49.15-- Loss:0.09 -- Acc:97.24\n",
      "Epoch:54 --Progress(%):73.86-- Loss:0.09 -- Acc:97.01\n",
      "Epoch:54 --Progress(%):98.58-- Loss:0.10 -- Acc:96.75\n",
      "Epoch:54 --Val Loss:0.46 -- Acc:87.36\n",
      "\n",
      "Epoch: 55\n",
      "Epoch:55 --Progress(%):24.43-- Loss:0.09 -- Acc:96.78\n",
      "Epoch:55 --Progress(%):49.15-- Loss:0.10 -- Acc:96.74\n",
      "Epoch:55 --Progress(%):73.86-- Loss:0.10 -- Acc:96.75\n",
      "Epoch:55 --Progress(%):98.58-- Loss:0.10 -- Acc:96.75\n",
      "Epoch:55 --Val Loss:0.42 -- Acc:87.98\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 56\n",
      "Epoch:56 --Progress(%):24.43-- Loss:0.08 -- Acc:97.34\n",
      "Epoch:56 --Progress(%):49.15-- Loss:0.08 -- Acc:97.17\n",
      "Epoch:56 --Progress(%):73.86-- Loss:0.09 -- Acc:97.07\n",
      "Epoch:56 --Progress(%):98.58-- Loss:0.09 -- Acc:96.99\n",
      "Epoch:56 --Val Loss:0.42 -- Acc:88.24\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 57\n",
      "Epoch:57 --Progress(%):24.43-- Loss:0.08 -- Acc:97.36\n",
      "Epoch:57 --Progress(%):49.15-- Loss:0.08 -- Acc:97.10\n",
      "Epoch:57 --Progress(%):73.86-- Loss:0.09 -- Acc:97.08\n",
      "Epoch:57 --Progress(%):98.58-- Loss:0.09 -- Acc:97.01\n",
      "Epoch:57 --Val Loss:0.44 -- Acc:86.92\n",
      "\n",
      "Epoch: 58\n",
      "Epoch:58 --Progress(%):24.43-- Loss:0.09 -- Acc:97.20\n",
      "Epoch:58 --Progress(%):49.15-- Loss:0.08 -- Acc:97.27\n",
      "Epoch:58 --Progress(%):73.86-- Loss:0.08 -- Acc:97.26\n",
      "Epoch:58 --Progress(%):98.58-- Loss:0.08 -- Acc:97.14\n",
      "Epoch:58 --Val Loss:0.43 -- Acc:87.34\n",
      "\n",
      "Epoch: 59\n",
      "Epoch:59 --Progress(%):24.43-- Loss:0.08 -- Acc:97.26\n",
      "Epoch:59 --Progress(%):49.15-- Loss:0.08 -- Acc:97.43\n",
      "Epoch:59 --Progress(%):73.86-- Loss:0.08 -- Acc:97.27\n",
      "Epoch:59 --Progress(%):98.58-- Loss:0.08 -- Acc:97.26\n",
      "Epoch:59 --Val Loss:0.41 -- Acc:87.90\n",
      "\n",
      "Epoch: 60\n",
      "Epoch:60 --Progress(%):24.43-- Loss:0.07 -- Acc:97.64\n",
      "Epoch:60 --Progress(%):49.15-- Loss:0.08 -- Acc:97.45\n",
      "Epoch:60 --Progress(%):73.86-- Loss:0.08 -- Acc:97.32\n",
      "Epoch:60 --Progress(%):98.58-- Loss:0.08 -- Acc:97.25\n",
      "Epoch:60 --Val Loss:0.42 -- Acc:87.84\n",
      "\n",
      "Epoch: 61\n",
      "Epoch:61 --Progress(%):24.43-- Loss:0.07 -- Acc:97.67\n",
      "Epoch:61 --Progress(%):49.15-- Loss:0.07 -- Acc:97.66\n",
      "Epoch:61 --Progress(%):73.86-- Loss:0.08 -- Acc:97.53\n",
      "Epoch:61 --Progress(%):98.58-- Loss:0.08 -- Acc:97.45\n",
      "Epoch:61 --Val Loss:0.42 -- Acc:88.00\n",
      "\n",
      "Epoch: 62\n",
      "Epoch:62 --Progress(%):24.43-- Loss:0.08 -- Acc:97.37\n",
      "Epoch:62 --Progress(%):49.15-- Loss:0.08 -- Acc:97.37\n",
      "Epoch:62 --Progress(%):73.86-- Loss:0.08 -- Acc:97.36\n",
      "Epoch:62 --Progress(%):98.58-- Loss:0.08 -- Acc:97.37\n",
      "Epoch:62 --Val Loss:0.41 -- Acc:88.32\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 63\n",
      "Epoch:63 --Progress(%):24.43-- Loss:0.07 -- Acc:97.81\n",
      "Epoch:63 --Progress(%):49.15-- Loss:0.07 -- Acc:97.75\n",
      "Epoch:63 --Progress(%):73.86-- Loss:0.07 -- Acc:97.69\n",
      "Epoch:63 --Progress(%):98.58-- Loss:0.07 -- Acc:97.59\n",
      "Epoch:63 --Val Loss:0.44 -- Acc:87.22\n",
      "\n",
      "Epoch: 64\n",
      "Epoch:64 --Progress(%):24.43-- Loss:0.07 -- Acc:97.66\n",
      "Epoch:64 --Progress(%):49.15-- Loss:0.07 -- Acc:97.75\n",
      "Epoch:64 --Progress(%):73.86-- Loss:0.07 -- Acc:97.68\n",
      "Epoch:64 --Progress(%):98.58-- Loss:0.07 -- Acc:97.62\n",
      "Epoch:64 --Val Loss:0.43 -- Acc:88.00\n",
      "\n",
      "Epoch: 65\n",
      "Epoch:65 --Progress(%):24.43-- Loss:0.06 -- Acc:97.87\n",
      "Epoch:65 --Progress(%):49.15-- Loss:0.06 -- Acc:97.82\n",
      "Epoch:65 --Progress(%):73.86-- Loss:0.07 -- Acc:97.71\n",
      "Epoch:65 --Progress(%):98.58-- Loss:0.07 -- Acc:97.68\n",
      "Epoch:65 --Val Loss:0.44 -- Acc:87.40\n",
      "\n",
      "Epoch: 66\n",
      "Epoch:66 --Progress(%):24.43-- Loss:0.07 -- Acc:97.67\n",
      "Epoch:66 --Progress(%):49.15-- Loss:0.07 -- Acc:97.83\n",
      "Epoch:66 --Progress(%):73.86-- Loss:0.07 -- Acc:97.86\n",
      "Epoch:66 --Progress(%):98.58-- Loss:0.07 -- Acc:97.77\n",
      "Epoch:66 --Val Loss:0.48 -- Acc:87.46\n",
      "\n",
      "Epoch: 67\n",
      "Epoch:67 --Progress(%):24.43-- Loss:0.06 -- Acc:97.88\n",
      "Epoch:67 --Progress(%):49.15-- Loss:0.06 -- Acc:97.87\n",
      "Epoch:67 --Progress(%):73.86-- Loss:0.06 -- Acc:97.90\n",
      "Epoch:67 --Progress(%):98.58-- Loss:0.07 -- Acc:97.84\n",
      "Epoch:67 --Val Loss:0.49 -- Acc:86.46\n",
      "\n",
      "Epoch: 68\n",
      "Epoch:68 --Progress(%):24.43-- Loss:0.07 -- Acc:97.80\n",
      "Epoch:68 --Progress(%):49.15-- Loss:0.06 -- Acc:97.89\n",
      "Epoch:68 --Progress(%):73.86-- Loss:0.06 -- Acc:97.92\n",
      "Epoch:68 --Progress(%):98.58-- Loss:0.07 -- Acc:97.80\n",
      "Epoch:68 --Val Loss:0.43 -- Acc:87.96\n",
      "\n",
      "Epoch: 69\n",
      "Epoch:69 --Progress(%):24.43-- Loss:0.06 -- Acc:98.11\n",
      "Epoch:69 --Progress(%):49.15-- Loss:0.06 -- Acc:98.02\n",
      "Epoch:69 --Progress(%):73.86-- Loss:0.06 -- Acc:98.02\n",
      "Epoch:69 --Progress(%):98.58-- Loss:0.06 -- Acc:97.99\n",
      "Epoch:69 --Val Loss:0.48 -- Acc:87.12\n",
      "\n",
      "Epoch: 70\n",
      "Epoch:70 --Progress(%):24.43-- Loss:0.05 -- Acc:98.18\n",
      "Epoch:70 --Progress(%):49.15-- Loss:0.05 -- Acc:98.20\n",
      "Epoch:70 --Progress(%):73.86-- Loss:0.06 -- Acc:97.98\n",
      "Epoch:70 --Progress(%):98.58-- Loss:0.06 -- Acc:97.94\n",
      "Epoch:70 --Val Loss:0.47 -- Acc:87.54\n",
      "\n",
      "Epoch: 71\n",
      "Epoch:71 --Progress(%):24.43-- Loss:0.06 -- Acc:98.22\n",
      "Epoch:71 --Progress(%):49.15-- Loss:0.06 -- Acc:98.14\n",
      "Epoch:71 --Progress(%):73.86-- Loss:0.06 -- Acc:98.05\n",
      "Epoch:71 --Progress(%):98.58-- Loss:0.06 -- Acc:98.05\n",
      "Epoch:71 --Val Loss:0.44 -- Acc:88.30\n",
      "\n",
      "Epoch: 72\n",
      "Epoch:72 --Progress(%):24.43-- Loss:0.05 -- Acc:98.29\n",
      "Epoch:72 --Progress(%):49.15-- Loss:0.05 -- Acc:98.33\n",
      "Epoch:72 --Progress(%):73.86-- Loss:0.06 -- Acc:98.08\n",
      "Epoch:72 --Progress(%):98.58-- Loss:0.06 -- Acc:97.90\n",
      "Epoch:72 --Val Loss:0.44 -- Acc:88.12\n",
      "\n",
      "Epoch: 73\n",
      "Epoch:73 --Progress(%):24.43-- Loss:0.06 -- Acc:98.13\n",
      "Epoch:73 --Progress(%):49.15-- Loss:0.05 -- Acc:98.28\n",
      "Epoch:73 --Progress(%):73.86-- Loss:0.05 -- Acc:98.20\n",
      "Epoch:73 --Progress(%):98.58-- Loss:0.06 -- Acc:98.17\n",
      "Epoch:73 --Val Loss:0.44 -- Acc:88.40\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 74\n",
      "Epoch:74 --Progress(%):24.43-- Loss:0.05 -- Acc:98.29\n",
      "Epoch:74 --Progress(%):49.15-- Loss:0.05 -- Acc:98.23\n",
      "Epoch:74 --Progress(%):73.86-- Loss:0.05 -- Acc:98.23\n",
      "Epoch:74 --Progress(%):98.58-- Loss:0.05 -- Acc:98.28\n",
      "Epoch:74 --Val Loss:0.42 -- Acc:88.32\n",
      "\n",
      "Epoch: 75\n",
      "Epoch:75 --Progress(%):24.43-- Loss:0.05 -- Acc:98.45\n",
      "Epoch:75 --Progress(%):49.15-- Loss:0.05 -- Acc:98.49\n",
      "Epoch:75 --Progress(%):73.86-- Loss:0.05 -- Acc:98.41\n",
      "Epoch:75 --Progress(%):98.58-- Loss:0.05 -- Acc:98.30\n",
      "Epoch:75 --Val Loss:0.42 -- Acc:88.66\n",
      "Saving the best model.\n",
      "\n",
      "Epoch: 76\n",
      "Epoch:76 --Progress(%):24.43-- Loss:0.05 -- Acc:98.42\n",
      "Epoch:76 --Progress(%):49.15-- Loss:0.05 -- Acc:98.35\n",
      "Epoch:76 --Progress(%):73.86-- Loss:0.05 -- Acc:98.28\n",
      "Epoch:76 --Progress(%):98.58-- Loss:0.05 -- Acc:98.23\n",
      "Epoch:76 --Val Loss:0.43 -- Acc:88.52\n",
      "\n",
      "Epoch: 77\n",
      "Epoch:77 --Progress(%):24.43-- Loss:0.05 -- Acc:98.23\n",
      "Epoch:77 --Progress(%):49.15-- Loss:0.05 -- Acc:98.24\n",
      "Epoch:77 --Progress(%):73.86-- Loss:0.05 -- Acc:98.25\n",
      "Epoch:77 --Progress(%):98.58-- Loss:0.05 -- Acc:98.27\n",
      "Epoch:77 --Val Loss:0.44 -- Acc:88.22\n",
      "\n",
      "Epoch: 78\n",
      "Epoch:78 --Progress(%):24.43-- Loss:0.05 -- Acc:98.52\n",
      "Epoch:78 --Progress(%):49.15-- Loss:0.05 -- Acc:98.62\n",
      "Epoch:78 --Progress(%):73.86-- Loss:0.05 -- Acc:98.61\n",
      "Epoch:78 --Progress(%):98.58-- Loss:0.05 -- Acc:98.59\n",
      "Epoch:78 --Val Loss:0.44 -- Acc:88.54\n",
      "\n",
      "Epoch: 79\n",
      "Epoch:79 --Progress(%):24.43-- Loss:0.04 -- Acc:98.70\n",
      "Epoch:79 --Progress(%):49.15-- Loss:0.04 -- Acc:98.65\n",
      "Epoch:79 --Progress(%):73.86-- Loss:0.05 -- Acc:98.55\n",
      "Epoch:79 --Progress(%):98.58-- Loss:0.05 -- Acc:98.46\n",
      "Epoch:79 --Val Loss:0.45 -- Acc:88.26\n",
      "***** Begin testing *****\n",
      "Epoch:79 --Test Loss:0.42 -- Acc:88.91\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+80):\n",
    "    train(epoch)\n",
    "    scheduler.step()\n",
    "    val(epoch)\n",
    "    \n",
    "test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0163e-a796-48f2-b133-2ae099412242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
