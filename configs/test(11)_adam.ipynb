{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ee83389f-a9b3-4864-a82d-e657fcdfccea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee83389f-a9b3-4864-a82d-e657fcdfccea",
        "outputId": "712b48a8-6a60-43ba-f5c8-c23b9e03bddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "51d931f3-2a00-4d16-822c-65dcca2492a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51d931f3-2a00-4d16-822c-65dcca2492a2",
        "outputId": "275fe986-e3a9-45ae-c940-a7292abc2f90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "15c317c6-2f13-484c-990d-0e785c7ff542",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15c317c6-2f13-484c-990d-0e785c7ff542",
        "outputId": "1bf6f766-aef7-42cf-d6f4-66dc79d00230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.15\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d473436e-81e6-43e0-a927-828bcdb6ad2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d473436e-81e6-43e0-a927-828bcdb6ad2b",
        "outputId": "1d41b689-9400-4807-e5b5-15867b0c1efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7ace70f8-a75d-47b4-bb0b-3ad2def6fd31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ace70f8-a75d-47b4-bb0b-3ad2def6fd31",
        "outputId": "69d7d0d7-45b6-497f-c3e6-1cbfeca3bdff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ab4a5f4c-8c99-4d39-a042-781a254d4db9",
      "metadata": {
        "id": "ab4a5f4c-8c99-4d39-a042-781a254d4db9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "45a66186-de75-4999-bd6c-44495ae9bcaa",
      "metadata": {
        "id": "45a66186-de75-4999-bd6c-44495ae9bcaa"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ed650fde-34c5-4b22-9dda-8980b42bf29d",
      "metadata": {
        "id": "ed650fde-34c5-4b22-9dda-8980b42bf29d"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8c12b5c0-fa20-4234-883c-3d95f6c94ad1",
      "metadata": {
        "id": "8c12b5c0-fa20-4234-883c-3d95f6c94ad1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "#_, term_width = os.popen('stty size', 'r').read().split()\n",
        "#term_width = int(term_width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e61711b0-b777-4a4b-ae45-7122cdedebf3",
      "metadata": {
        "id": "e61711b0-b777-4a4b-ae45-7122cdedebf3"
      },
      "outputs": [],
      "source": [
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "47534613-4523-4906-b70d-dc4358fbd305",
      "metadata": {
        "id": "47534613-4523-4906-b70d-dc4358fbd305"
      },
      "outputs": [],
      "source": [
        "#from utils import progress_bar\n",
        "\n",
        "TOTAL_BAR_LENGTH = 65.\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0be2910c-4a57-4dc3-8a92-8f27eb0a7361",
      "metadata": {
        "id": "0be2910c-4a57-4dc3-8a92-8f27eb0a7361"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "70a8e21e-f374-4e19-a2a1-6b6fc732bdce",
      "metadata": {
        "id": "70a8e21e-f374-4e19-a2a1-6b6fc732bdce"
      },
      "outputs": [],
      "source": [
        "start_epoch = 0\n",
        "best_acc = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9fdb57ad-a400-47b1-b36d-583b1c447086",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fdb57ad-a400-47b1-b36d-583b1c447086",
        "outputId": "48f7222f-5379-4eca-8c65-ff934a7ff08a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n"
          ]
        }
      ],
      "source": [
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e3338aad-e23d-41a5-b983-54216f8e5635",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "d47c406849d845d1b14a36c3431faad2",
            "e4924cd9ce7045bd9377db91b5975171",
            "e6887cbe5bb8469b843faacad8f14726",
            "542cd4293ccb431d9e5714e1cf8e9f59",
            "65da4998ce6e4acd950cd7540276f9d2",
            "5589772f63404758bb514a1f455a2aaf",
            "5f9a78aaa1be4a8da4b6014779da7ac8",
            "938ad89668d042758513ca615f710668",
            "4110dffcb8be4d4e9393ca222bd903f5",
            "2cabf17df33e491d961a89b752d5a7d5",
            "2b8237af6f464b7dad2ab4959e8c70e4"
          ]
        },
        "id": "e3338aad-e23d-41a5-b983-54216f8e5635",
        "outputId": "9a7b0721-4cb7-4557-e358-8bcf0a4c6865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d47c406849d845d1b14a36c3431faad2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1f911a57-de25-4e39-8a34-b1c5c1872997",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f911a57-de25-4e39-8a34-b1c5c1872997",
        "outputId": "26e8fa9b-f5ca-48c2-8ab2-ce3611859060"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomCrop(size=(32, 32), padding=4)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "trainset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cc41d0d0-af5c-46a3-b94a-053234cd9f74",
      "metadata": {
        "id": "cc41d0d0-af5c-46a3-b94a-053234cd9f74"
      },
      "outputs": [],
      "source": [
        "VALID_RATIO = 0.9\n",
        "\n",
        "n_train_examples = int(len(trainset) * VALID_RATIO)\n",
        "n_valid_examples = len(trainset) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(trainset, \n",
        "                                           [n_train_examples, n_valid_examples])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8b1b400f-6419-459f-a53b-162b808ed6e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b1b400f-6419-459f-a53b-162b808ed6e3",
        "outputId": "9d632375-53da-43e3-8ef7-8d7ea9929bfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7ff3620b3050>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "14a917b4-94a4-46c6-af04-348e499d94e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14a917b4-94a4-46c6-af04-348e499d94e9",
        "outputId": "2469df9f-ec0b-4b13-ccf9-4f69024f1734"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7ff3ed7667d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1ac0c4b4-b0ae-496a-81eb-81c68fd3e434",
      "metadata": {
        "id": "1ac0c4b4-b0ae-496a-81eb-81c68fd3e434"
      },
      "outputs": [],
      "source": [
        "trainset=train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a00cfce4-75c7-456e-a2f8-4ca097e2919d",
      "metadata": {
        "id": "a00cfce4-75c7-456e-a2f8-4ca097e2919d"
      },
      "outputs": [],
      "source": [
        "valset = valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3906e02d-7556-499f-a57e-b524a5e22c82",
      "metadata": {
        "id": "3906e02d-7556-499f-a57e-b524a5e22c82"
      },
      "outputs": [],
      "source": [
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4b1af921-5eed-4670-8a9c-4cc3b79d5b5d",
      "metadata": {
        "id": "4b1af921-5eed-4670-8a9c-4cc3b79d5b5d"
      },
      "outputs": [],
      "source": [
        "valloader = torch.utils.data.DataLoader(\n",
        "    valset, batch_size=128, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "24e9ac75-8935-479c-865d-cea4b6c80989",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24e9ac75-8935-479c-865d-cea4b6c80989",
        "outputId": "af6cef1b-1bdd-4953-e689-0cf1b1169618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6ca8cdba-ad41-41af-9fb6-d44acc55ec3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ca8cdba-ad41-41af-9fb6-d44acc55ec3c",
        "outputId": "c3b67197-b0d3-42c0-a69f-2add9cbb1f32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "85925983-5638-4fdf-afb7-ac458dd1b48e",
      "metadata": {
        "id": "85925983-5638-4fdf-afb7-ac458dd1b48e"
      },
      "outputs": [],
      "source": [
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "afec1542-188b-4404-b100-3a165a77187b",
      "metadata": {
        "id": "afec1542-188b-4404-b100-3a165a77187b"
      },
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "405399b9-f69e-4347-9b8d-20eb392cbebe",
      "metadata": {
        "id": "405399b9-f69e-4347-9b8d-20eb392cbebe"
      },
      "outputs": [],
      "source": [
        "## model to use\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        \"\"\"\n",
        "        in_planes: C_in for conv1 and Sequential.Conv2d\n",
        "        planes: F_i\n",
        "        \"\"\"\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    #expansion = 2\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False) # since kernel is 1 padding is 0\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False) # size doesn't change here\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=3, stride=stride, padding=0, bias=False) #original kernel was 1\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        #self.shortcut = nn.Sequential()\n",
        "        #if stride != 1 or in_planes != self.expansion*planes:\n",
        "        self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=3, stride=stride, padding =0, bias=False), # stride was 1\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks,  num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 32\n",
        "        \"\"\"\n",
        "        in_planes: C_out of layer1\n",
        "        \"\"\"\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "            \"\"\"\n",
        "            in_planes becomes the output of the current layer\n",
        "            \"\"\"\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 5) # to be understood\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def ResNet18bottleneck():  ## using this in this run\n",
        "    return ResNet(Bottleneck, [2, 2, 1, 1])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "77265181-9721-4b74-bf4a-b877d9ea1daa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77265181-9721-4b74-bf4a-b877d9ea1daa",
        "outputId": "a75875e4-a7e5-416e-ddea-c54b2f5a1aa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n"
          ]
        }
      ],
      "source": [
        "print('==> Building model..')\n",
        "#net = ResNet18()\n",
        "net = ResNet18bottleneck()\n",
        "net = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "fa466e14-a159-4648-b890-00890d0ddf4c",
      "metadata": {
        "id": "fa466e14-a159-4648-b890-00890d0ddf4c"
      },
      "outputs": [],
      "source": [
        "#!pip install torch-summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "081f146e-e788-4e7c-8fb5-fa7348ddd103",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "081f146e-e788-4e7c-8fb5-fa7348ddd103",
        "outputId": "ae7f48a5-f5df-4104-bf6a-4db035dd0c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "            Conv2d-3           [-1, 64, 32, 32]           2,048\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "            Conv2d-7           [-1, 64, 30, 30]          36,864\n",
            "       BatchNorm2d-8           [-1, 64, 30, 30]             128\n",
            "            Conv2d-9           [-1, 64, 30, 30]          18,432\n",
            "      BatchNorm2d-10           [-1, 64, 30, 30]             128\n",
            "       Bottleneck-11           [-1, 64, 30, 30]               0\n",
            "           Conv2d-12           [-1, 64, 30, 30]           4,096\n",
            "      BatchNorm2d-13           [-1, 64, 30, 30]             128\n",
            "           Conv2d-14           [-1, 64, 30, 30]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 30, 30]             128\n",
            "           Conv2d-16           [-1, 64, 28, 28]          36,864\n",
            "      BatchNorm2d-17           [-1, 64, 28, 28]             128\n",
            "           Conv2d-18           [-1, 64, 28, 28]          36,864\n",
            "      BatchNorm2d-19           [-1, 64, 28, 28]             128\n",
            "       Bottleneck-20           [-1, 64, 28, 28]               0\n",
            "           Conv2d-21          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-22          [-1, 128, 28, 28]             256\n",
            "           Conv2d-23          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
            "           Conv2d-25          [-1, 128, 26, 26]         147,456\n",
            "      BatchNorm2d-26          [-1, 128, 26, 26]             256\n",
            "           Conv2d-27          [-1, 128, 26, 26]          73,728\n",
            "      BatchNorm2d-28          [-1, 128, 26, 26]             256\n",
            "       Bottleneck-29          [-1, 128, 26, 26]               0\n",
            "           Conv2d-30          [-1, 128, 26, 26]          16,384\n",
            "      BatchNorm2d-31          [-1, 128, 26, 26]             256\n",
            "           Conv2d-32          [-1, 128, 26, 26]         147,456\n",
            "      BatchNorm2d-33          [-1, 128, 26, 26]             256\n",
            "           Conv2d-34          [-1, 128, 24, 24]         147,456\n",
            "      BatchNorm2d-35          [-1, 128, 24, 24]             256\n",
            "           Conv2d-36          [-1, 128, 24, 24]         147,456\n",
            "      BatchNorm2d-37          [-1, 128, 24, 24]             256\n",
            "       Bottleneck-38          [-1, 128, 24, 24]               0\n",
            "           Conv2d-39          [-1, 128, 24, 24]          16,384\n",
            "      BatchNorm2d-40          [-1, 128, 24, 24]             256\n",
            "           Conv2d-41          [-1, 128, 24, 24]         147,456\n",
            "      BatchNorm2d-42          [-1, 128, 24, 24]             256\n",
            "           Conv2d-43          [-1, 128, 11, 11]         147,456\n",
            "      BatchNorm2d-44          [-1, 128, 11, 11]             256\n",
            "           Conv2d-45          [-1, 128, 11, 11]         147,456\n",
            "      BatchNorm2d-46          [-1, 128, 11, 11]             256\n",
            "       Bottleneck-47          [-1, 128, 11, 11]               0\n",
            "           Conv2d-48          [-1, 256, 11, 11]          32,768\n",
            "      BatchNorm2d-49          [-1, 256, 11, 11]             512\n",
            "           Conv2d-50          [-1, 256, 11, 11]         589,824\n",
            "      BatchNorm2d-51          [-1, 256, 11, 11]             512\n",
            "           Conv2d-52            [-1, 256, 5, 5]         589,824\n",
            "      BatchNorm2d-53            [-1, 256, 5, 5]             512\n",
            "           Conv2d-54            [-1, 256, 5, 5]         294,912\n",
            "      BatchNorm2d-55            [-1, 256, 5, 5]             512\n",
            "       Bottleneck-56            [-1, 256, 5, 5]               0\n",
            "           Linear-57                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 3,020,202\n",
            "Trainable params: 3,020,202\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 24.22\n",
            "Params size (MB): 11.52\n",
            "Estimated Total Size (MB): 35.75\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "## For our model\n",
        "from torchsummary import summary\n",
        "summary(net, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ce8ed088-442d-42f1-ad45-a6f0b0435a16",
      "metadata": {
        "id": "ce8ed088-442d-42f1-ad45-a6f0b0435a16"
      },
      "outputs": [],
      "source": [
        "#original model only for reference\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)  # same as the last layer's HxW\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "312ac932-4c35-48bf-8eeb-936a42ba6be0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "312ac932-4c35-48bf-8eeb-936a42ba6be0",
        "outputId": "4943eba6-60ce-4a04-f620-4fd856fc7ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
            "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.25\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 53.89\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "originalNet = ResNet18()\n",
        "summary(originalNet.cuda(), input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "b2fee59c-356e-4823-9f55-1730dc72958d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2fee59c-356e-4823-9f55-1730dc72958d",
        "outputId": "5bef8fcb-9165-4728-e6fc-62e123316af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "            Conv2d-3           [-1, 64, 32, 32]           2,048\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "            Conv2d-7           [-1, 64, 30, 30]          36,864\n",
            "       BatchNorm2d-8           [-1, 64, 30, 30]             128\n",
            "            Conv2d-9           [-1, 64, 30, 30]          18,432\n",
            "      BatchNorm2d-10           [-1, 64, 30, 30]             128\n",
            "       Bottleneck-11           [-1, 64, 30, 30]               0\n",
            "           Conv2d-12           [-1, 64, 30, 30]           4,096\n",
            "      BatchNorm2d-13           [-1, 64, 30, 30]             128\n",
            "           Conv2d-14           [-1, 64, 30, 30]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 30, 30]             128\n",
            "           Conv2d-16           [-1, 64, 28, 28]          36,864\n",
            "      BatchNorm2d-17           [-1, 64, 28, 28]             128\n",
            "           Conv2d-18           [-1, 64, 28, 28]          36,864\n",
            "      BatchNorm2d-19           [-1, 64, 28, 28]             128\n",
            "       Bottleneck-20           [-1, 64, 28, 28]               0\n",
            "           Conv2d-21          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-22          [-1, 128, 28, 28]             256\n",
            "           Conv2d-23          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
            "           Conv2d-25          [-1, 128, 26, 26]         147,456\n",
            "      BatchNorm2d-26          [-1, 128, 26, 26]             256\n",
            "           Conv2d-27          [-1, 128, 26, 26]          73,728\n",
            "      BatchNorm2d-28          [-1, 128, 26, 26]             256\n",
            "       Bottleneck-29          [-1, 128, 26, 26]               0\n",
            "           Conv2d-30          [-1, 128, 26, 26]          16,384\n",
            "      BatchNorm2d-31          [-1, 128, 26, 26]             256\n",
            "           Conv2d-32          [-1, 128, 26, 26]         147,456\n",
            "      BatchNorm2d-33          [-1, 128, 26, 26]             256\n",
            "           Conv2d-34          [-1, 128, 24, 24]         147,456\n",
            "      BatchNorm2d-35          [-1, 128, 24, 24]             256\n",
            "           Conv2d-36          [-1, 128, 24, 24]         147,456\n",
            "      BatchNorm2d-37          [-1, 128, 24, 24]             256\n",
            "       Bottleneck-38          [-1, 128, 24, 24]               0\n",
            "           Conv2d-39          [-1, 128, 24, 24]          16,384\n",
            "      BatchNorm2d-40          [-1, 128, 24, 24]             256\n",
            "           Conv2d-41          [-1, 128, 24, 24]         147,456\n",
            "      BatchNorm2d-42          [-1, 128, 24, 24]             256\n",
            "           Conv2d-43          [-1, 128, 11, 11]         147,456\n",
            "      BatchNorm2d-44          [-1, 128, 11, 11]             256\n",
            "           Conv2d-45          [-1, 128, 11, 11]         147,456\n",
            "      BatchNorm2d-46          [-1, 128, 11, 11]             256\n",
            "       Bottleneck-47          [-1, 128, 11, 11]               0\n",
            "           Conv2d-48          [-1, 256, 11, 11]          32,768\n",
            "      BatchNorm2d-49          [-1, 256, 11, 11]             512\n",
            "           Conv2d-50          [-1, 256, 11, 11]         589,824\n",
            "      BatchNorm2d-51          [-1, 256, 11, 11]             512\n",
            "           Conv2d-52            [-1, 256, 5, 5]         589,824\n",
            "      BatchNorm2d-53            [-1, 256, 5, 5]             512\n",
            "           Conv2d-54            [-1, 256, 5, 5]         294,912\n",
            "      BatchNorm2d-55            [-1, 256, 5, 5]             512\n",
            "       Bottleneck-56            [-1, 256, 5, 5]               0\n",
            "           Linear-57                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 3,020,202\n",
            "Trainable params: 3,020,202\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 24.22\n",
            "Params size (MB): 11.52\n",
            "Estimated Total Size (MB): 35.75\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "## For our model\n",
        "from torchsummary import summary\n",
        "summary(net, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7f0f1fa3-ccf1-4d27-9b5b-33e1f979f9d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7f0f1fa3-ccf1-4d27-9b5b-33e1f979f9d5",
        "outputId": "2e961fcb-38d6-48eb-c6ff-f84d35e4ed94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "11b9ddac-9903-4b60-bc43-c7575505c686",
      "metadata": {
        "id": "11b9ddac-9903-4b60-bc43-c7575505c686"
      },
      "outputs": [],
      "source": [
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5654e62c-fdca-4005-87d5-c626b83a5c0d",
      "metadata": {
        "id": "5654e62c-fdca-4005-87d5-c626b83a5c0d"
      },
      "outputs": [],
      "source": [
        "resume = False\n",
        "if resume == True:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    net.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "e666fc97-7784-4cdd-ac4d-ada985110509",
      "metadata": {
        "id": "e666fc97-7784-4cdd-ac4d-ada985110509"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0005,\n",
        "                      weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5c447abe-7a21-48c9-97ed-275e5764c6b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c447abe-7a21-48c9-97ed-275e5764c6b0",
        "outputId": "a5d7d364-87a3-4a8d-8586-6f6e6dfceccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "67dd76ba-2d61-4893-b3dc-49ae62d09e05",
      "metadata": {
        "id": "67dd76ba-2d61-4893-b3dc-49ae62d09e05"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "15511c65-995d-442b-9010-09c82ac28c1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15511c65-995d-442b-9010-09c82ac28c1c",
        "outputId": "7cf275a5-b62f-4137-d310-6926907ad26d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(trainloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "20fb231a-c978-4bfd-a4e3-be6cba4a8c70",
      "metadata": {
        "id": "20fb231a-c978-4bfd-a4e3-be6cba4a8c70"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    steps = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        steps = steps+1\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        #progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "        #             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "        if steps%87==0:\n",
        "            print(f\"Epoch:{epoch} --Progress(%):{batch_idx/len(trainloader)*100.:.2f}-- Loss:{train_loss/(batch_idx+1):.2f} -- Acc:{100.*correct/total:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "e401698b-798c-42b0-99e3-438ddcd89b47",
      "metadata": {
        "id": "e401698b-798c-42b0-99e3-438ddcd89b47"
      },
      "outputs": [],
      "source": [
        "def val(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            #progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            #             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    print(f\"Epoch:{epoch} --Val Loss:{val_loss/(batch_idx+1):.2f} -- Acc:{100.*correct/total:.2f}\")\n",
        "            \n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving the best model.')\n",
        "        #state = {\n",
        "        #    'net': net.state_dict(),\n",
        "        #    'acc': acc,\n",
        "        #    'epoch': epoch,\n",
        "        #}\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        #torch.save(state, './checkpoint/ckpt.pth')\n",
        "        \n",
        "        torch.save(net.state_dict(), './checkpoint/ckpt.pth')\n",
        "        best_acc = acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "b5cfb159-d153-41f3-b0e8-386264c8c939",
      "metadata": {
        "id": "b5cfb159-d153-41f3-b0e8-386264c8c939"
      },
      "outputs": [],
      "source": [
        "def test(epoch):\n",
        "    print(\"***** Begin testing *****\")\n",
        "    net.load_state_dict(torch.load('./checkpoint/ckpt.pth'))\n",
        "    net.eval()\n",
        "    \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            #progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            #             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    print(f\"Epoch:{epoch} --Test Loss:{test_loss/(batch_idx+1):.2f} -- Acc:{100.*correct/total:.2f}\")\n",
        "            \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9150bd92-d2ea-4a25-b6cb-ea7a312e2f08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9150bd92-d2ea-4a25-b6cb-ea7a312e2f08",
        "outputId": "be1f6a72-3b83-4a16-d505-485a078d8ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "Epoch:0 --Progress(%):24.43-- Loss:1.74 -- Acc:34.11\n",
            "Epoch:0 --Progress(%):49.15-- Loss:1.61 -- Acc:40.01\n",
            "Epoch:0 --Progress(%):73.86-- Loss:1.51 -- Acc:44.00\n",
            "Epoch:0 --Progress(%):98.58-- Loss:1.44 -- Acc:47.16\n",
            "Epoch:0 --Val Loss:1.20 -- Acc:56.74\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 1\n",
            "Epoch:1 --Progress(%):24.43-- Loss:1.09 -- Acc:61.07\n",
            "Epoch:1 --Progress(%):49.15-- Loss:1.07 -- Acc:61.71\n",
            "Epoch:1 --Progress(%):73.86-- Loss:1.04 -- Acc:62.80\n",
            "Epoch:1 --Progress(%):98.58-- Loss:1.02 -- Acc:63.62\n",
            "Epoch:1 --Val Loss:1.29 -- Acc:57.76\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 2\n",
            "Epoch:2 --Progress(%):24.43-- Loss:0.91 -- Acc:67.57\n",
            "Epoch:2 --Progress(%):49.15-- Loss:0.89 -- Acc:68.75\n",
            "Epoch:2 --Progress(%):73.86-- Loss:0.87 -- Acc:69.38\n",
            "Epoch:2 --Progress(%):98.58-- Loss:0.86 -- Acc:69.79\n",
            "Epoch:2 --Val Loss:0.88 -- Acc:69.40\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 3\n",
            "Epoch:3 --Progress(%):24.43-- Loss:0.76 -- Acc:73.20\n",
            "Epoch:3 --Progress(%):49.15-- Loss:0.76 -- Acc:73.60\n",
            "Epoch:3 --Progress(%):73.86-- Loss:0.75 -- Acc:73.64\n",
            "Epoch:3 --Progress(%):98.58-- Loss:0.74 -- Acc:74.01\n",
            "Epoch:3 --Val Loss:0.74 -- Acc:74.50\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 4\n",
            "Epoch:4 --Progress(%):24.43-- Loss:0.69 -- Acc:76.15\n",
            "Epoch:4 --Progress(%):49.15-- Loss:0.68 -- Acc:76.40\n",
            "Epoch:4 --Progress(%):73.86-- Loss:0.68 -- Acc:76.58\n",
            "Epoch:4 --Progress(%):98.58-- Loss:0.67 -- Acc:76.77\n",
            "Epoch:4 --Val Loss:0.76 -- Acc:73.50\n",
            "\n",
            "Epoch: 5\n",
            "Epoch:5 --Progress(%):24.43-- Loss:0.61 -- Acc:79.28\n",
            "Epoch:5 --Progress(%):49.15-- Loss:0.62 -- Acc:78.94\n",
            "Epoch:5 --Progress(%):73.86-- Loss:0.62 -- Acc:78.86\n",
            "Epoch:5 --Progress(%):98.58-- Loss:0.61 -- Acc:78.93\n",
            "Epoch:5 --Val Loss:0.86 -- Acc:71.18\n",
            "\n",
            "Epoch: 6\n",
            "Epoch:6 --Progress(%):24.43-- Loss:0.56 -- Acc:80.52\n",
            "Epoch:6 --Progress(%):49.15-- Loss:0.57 -- Acc:80.30\n",
            "Epoch:6 --Progress(%):73.86-- Loss:0.57 -- Acc:80.40\n",
            "Epoch:6 --Progress(%):98.58-- Loss:0.57 -- Acc:80.43\n",
            "Epoch:6 --Val Loss:0.84 -- Acc:72.36\n",
            "\n",
            "Epoch: 7\n",
            "Epoch:7 --Progress(%):24.43-- Loss:0.53 -- Acc:81.82\n",
            "Epoch:7 --Progress(%):49.15-- Loss:0.53 -- Acc:81.69\n",
            "Epoch:7 --Progress(%):73.86-- Loss:0.53 -- Acc:81.55\n",
            "Epoch:7 --Progress(%):98.58-- Loss:0.53 -- Acc:81.54\n",
            "Epoch:7 --Val Loss:0.67 -- Acc:77.62\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 8\n",
            "Epoch:8 --Progress(%):24.43-- Loss:0.50 -- Acc:82.73\n",
            "Epoch:8 --Progress(%):49.15-- Loss:0.50 -- Acc:82.75\n",
            "Epoch:8 --Progress(%):73.86-- Loss:0.50 -- Acc:82.67\n",
            "Epoch:8 --Progress(%):98.58-- Loss:0.50 -- Acc:82.57\n",
            "Epoch:8 --Val Loss:0.72 -- Acc:75.94\n",
            "\n",
            "Epoch: 9\n",
            "Epoch:9 --Progress(%):24.43-- Loss:0.46 -- Acc:84.46\n",
            "Epoch:9 --Progress(%):49.15-- Loss:0.47 -- Acc:83.74\n",
            "Epoch:9 --Progress(%):73.86-- Loss:0.48 -- Acc:83.59\n",
            "Epoch:9 --Progress(%):98.58-- Loss:0.48 -- Acc:83.47\n",
            "Epoch:9 --Val Loss:0.59 -- Acc:79.80\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 10\n",
            "Epoch:10 --Progress(%):24.43-- Loss:0.44 -- Acc:85.15\n",
            "Epoch:10 --Progress(%):49.15-- Loss:0.45 -- Acc:84.91\n",
            "Epoch:10 --Progress(%):73.86-- Loss:0.45 -- Acc:84.77\n",
            "Epoch:10 --Progress(%):98.58-- Loss:0.45 -- Acc:84.53\n",
            "Epoch:10 --Val Loss:0.71 -- Acc:76.04\n",
            "\n",
            "Epoch: 11\n",
            "Epoch:11 --Progress(%):24.43-- Loss:0.42 -- Acc:85.32\n",
            "Epoch:11 --Progress(%):49.15-- Loss:0.42 -- Acc:85.42\n",
            "Epoch:11 --Progress(%):73.86-- Loss:0.43 -- Acc:85.19\n",
            "Epoch:11 --Progress(%):98.58-- Loss:0.43 -- Acc:85.19\n",
            "Epoch:11 --Val Loss:0.63 -- Acc:80.20\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 12\n",
            "Epoch:12 --Progress(%):24.43-- Loss:0.40 -- Acc:86.48\n",
            "Epoch:12 --Progress(%):49.15-- Loss:0.40 -- Acc:86.26\n",
            "Epoch:12 --Progress(%):73.86-- Loss:0.41 -- Acc:86.04\n",
            "Epoch:12 --Progress(%):98.58-- Loss:0.41 -- Acc:85.86\n",
            "Epoch:12 --Val Loss:0.69 -- Acc:77.12\n",
            "\n",
            "Epoch: 13\n",
            "Epoch:13 --Progress(%):24.43-- Loss:0.38 -- Acc:86.93\n",
            "Epoch:13 --Progress(%):49.15-- Loss:0.39 -- Acc:86.78\n",
            "Epoch:13 --Progress(%):73.86-- Loss:0.39 -- Acc:86.74\n",
            "Epoch:13 --Progress(%):98.58-- Loss:0.40 -- Acc:86.27\n",
            "Epoch:13 --Val Loss:0.58 -- Acc:81.68\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 14\n",
            "Epoch:14 --Progress(%):24.43-- Loss:0.36 -- Acc:87.63\n",
            "Epoch:14 --Progress(%):49.15-- Loss:0.37 -- Acc:87.41\n",
            "Epoch:14 --Progress(%):73.86-- Loss:0.38 -- Acc:87.17\n",
            "Epoch:14 --Progress(%):98.58-- Loss:0.38 -- Acc:86.91\n",
            "Epoch:14 --Val Loss:0.55 -- Acc:82.30\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 15\n",
            "Epoch:15 --Progress(%):24.43-- Loss:0.35 -- Acc:88.07\n",
            "Epoch:15 --Progress(%):49.15-- Loss:0.35 -- Acc:87.72\n",
            "Epoch:15 --Progress(%):73.86-- Loss:0.36 -- Acc:87.61\n",
            "Epoch:15 --Progress(%):98.58-- Loss:0.37 -- Acc:87.42\n",
            "Epoch:15 --Val Loss:0.48 -- Acc:83.58\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 16\n",
            "Epoch:16 --Progress(%):24.43-- Loss:0.34 -- Acc:88.17\n",
            "Epoch:16 --Progress(%):49.15-- Loss:0.36 -- Acc:87.80\n",
            "Epoch:16 --Progress(%):73.86-- Loss:0.35 -- Acc:87.86\n",
            "Epoch:16 --Progress(%):98.58-- Loss:0.36 -- Acc:87.75\n",
            "Epoch:16 --Val Loss:0.60 -- Acc:79.62\n",
            "\n",
            "Epoch: 17\n",
            "Epoch:17 --Progress(%):24.43-- Loss:0.32 -- Acc:89.18\n",
            "Epoch:17 --Progress(%):49.15-- Loss:0.33 -- Acc:88.80\n",
            "Epoch:17 --Progress(%):73.86-- Loss:0.33 -- Acc:88.77\n",
            "Epoch:17 --Progress(%):98.58-- Loss:0.34 -- Acc:88.48\n",
            "Epoch:17 --Val Loss:0.52 -- Acc:82.28\n",
            "\n",
            "Epoch: 18\n",
            "Epoch:18 --Progress(%):24.43-- Loss:0.32 -- Acc:88.69\n",
            "Epoch:18 --Progress(%):49.15-- Loss:0.32 -- Acc:88.90\n",
            "Epoch:18 --Progress(%):73.86-- Loss:0.33 -- Acc:88.83\n",
            "Epoch:18 --Progress(%):98.58-- Loss:0.33 -- Acc:88.72\n",
            "Epoch:18 --Val Loss:0.52 -- Acc:82.76\n",
            "\n",
            "Epoch: 19\n",
            "Epoch:19 --Progress(%):24.43-- Loss:0.31 -- Acc:89.80\n",
            "Epoch:19 --Progress(%):49.15-- Loss:0.31 -- Acc:89.38\n",
            "Epoch:19 --Progress(%):73.86-- Loss:0.32 -- Acc:89.30\n",
            "Epoch:19 --Progress(%):98.58-- Loss:0.32 -- Acc:89.18\n",
            "Epoch:19 --Val Loss:0.64 -- Acc:79.82\n",
            "\n",
            "Epoch: 20\n",
            "Epoch:20 --Progress(%):24.43-- Loss:0.30 -- Acc:89.69\n",
            "Epoch:20 --Progress(%):49.15-- Loss:0.31 -- Acc:89.31\n",
            "Epoch:20 --Progress(%):73.86-- Loss:0.31 -- Acc:89.34\n",
            "Epoch:20 --Progress(%):98.58-- Loss:0.31 -- Acc:89.42\n",
            "Epoch:20 --Val Loss:0.57 -- Acc:81.06\n",
            "\n",
            "Epoch: 21\n",
            "Epoch:21 --Progress(%):24.43-- Loss:0.29 -- Acc:90.22\n",
            "Epoch:21 --Progress(%):49.15-- Loss:0.29 -- Acc:90.16\n",
            "Epoch:21 --Progress(%):73.86-- Loss:0.29 -- Acc:90.04\n",
            "Epoch:21 --Progress(%):98.58-- Loss:0.30 -- Acc:89.81\n",
            "Epoch:21 --Val Loss:0.51 -- Acc:82.90\n",
            "\n",
            "Epoch: 22\n",
            "Epoch:22 --Progress(%):24.43-- Loss:0.27 -- Acc:90.67\n",
            "Epoch:22 --Progress(%):49.15-- Loss:0.28 -- Acc:90.41\n",
            "Epoch:22 --Progress(%):73.86-- Loss:0.29 -- Acc:90.18\n",
            "Epoch:22 --Progress(%):98.58-- Loss:0.29 -- Acc:90.02\n",
            "Epoch:22 --Val Loss:0.46 -- Acc:84.90\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 23\n",
            "Epoch:23 --Progress(%):24.43-- Loss:0.26 -- Acc:91.28\n",
            "Epoch:23 --Progress(%):49.15-- Loss:0.27 -- Acc:91.01\n",
            "Epoch:23 --Progress(%):73.86-- Loss:0.28 -- Acc:90.69\n",
            "Epoch:23 --Progress(%):98.58-- Loss:0.28 -- Acc:90.39\n",
            "Epoch:23 --Val Loss:0.52 -- Acc:82.88\n",
            "\n",
            "Epoch: 24\n",
            "Epoch:24 --Progress(%):24.43-- Loss:0.27 -- Acc:90.48\n",
            "Epoch:24 --Progress(%):49.15-- Loss:0.27 -- Acc:90.60\n",
            "Epoch:24 --Progress(%):73.86-- Loss:0.27 -- Acc:90.55\n",
            "Epoch:24 --Progress(%):98.58-- Loss:0.28 -- Acc:90.48\n",
            "Epoch:24 --Val Loss:0.55 -- Acc:82.10\n",
            "\n",
            "Epoch: 25\n",
            "Epoch:25 --Progress(%):24.43-- Loss:0.25 -- Acc:91.54\n",
            "Epoch:25 --Progress(%):49.15-- Loss:0.26 -- Acc:91.21\n",
            "Epoch:25 --Progress(%):73.86-- Loss:0.26 -- Acc:91.02\n",
            "Epoch:25 --Progress(%):98.58-- Loss:0.27 -- Acc:90.78\n",
            "Epoch:25 --Val Loss:0.44 -- Acc:85.38\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 26\n",
            "Epoch:26 --Progress(%):24.43-- Loss:0.24 -- Acc:91.74\n",
            "Epoch:26 --Progress(%):49.15-- Loss:0.25 -- Acc:91.36\n",
            "Epoch:26 --Progress(%):73.86-- Loss:0.26 -- Acc:91.19\n",
            "Epoch:26 --Progress(%):98.58-- Loss:0.26 -- Acc:91.05\n",
            "Epoch:26 --Val Loss:0.45 -- Acc:84.24\n",
            "\n",
            "Epoch: 27\n",
            "Epoch:27 --Progress(%):24.43-- Loss:0.23 -- Acc:91.97\n",
            "Epoch:27 --Progress(%):49.15-- Loss:0.25 -- Acc:91.58\n",
            "Epoch:27 --Progress(%):73.86-- Loss:0.25 -- Acc:91.43\n",
            "Epoch:27 --Progress(%):98.58-- Loss:0.25 -- Acc:91.29\n",
            "Epoch:27 --Val Loss:0.44 -- Acc:85.46\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 28\n",
            "Epoch:28 --Progress(%):24.43-- Loss:0.24 -- Acc:91.80\n",
            "Epoch:28 --Progress(%):49.15-- Loss:0.24 -- Acc:91.62\n",
            "Epoch:28 --Progress(%):73.86-- Loss:0.24 -- Acc:91.59\n",
            "Epoch:28 --Progress(%):98.58-- Loss:0.25 -- Acc:91.46\n",
            "Epoch:28 --Val Loss:0.52 -- Acc:83.36\n",
            "\n",
            "Epoch: 29\n",
            "Epoch:29 --Progress(%):24.43-- Loss:0.22 -- Acc:92.56\n",
            "Epoch:29 --Progress(%):49.15-- Loss:0.23 -- Acc:92.29\n",
            "Epoch:29 --Progress(%):73.86-- Loss:0.23 -- Acc:92.11\n",
            "Epoch:29 --Progress(%):98.58-- Loss:0.24 -- Acc:91.78\n",
            "Epoch:29 --Val Loss:0.44 -- Acc:85.80\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 30\n",
            "Epoch:30 --Progress(%):24.43-- Loss:0.21 -- Acc:93.18\n",
            "Epoch:30 --Progress(%):49.15-- Loss:0.22 -- Acc:92.62\n",
            "Epoch:30 --Progress(%):73.86-- Loss:0.23 -- Acc:92.36\n",
            "Epoch:30 --Progress(%):98.58-- Loss:0.23 -- Acc:92.09\n",
            "Epoch:30 --Val Loss:0.51 -- Acc:83.40\n",
            "\n",
            "Epoch: 31\n",
            "Epoch:31 --Progress(%):24.43-- Loss:0.21 -- Acc:92.60\n",
            "Epoch:31 --Progress(%):49.15-- Loss:0.22 -- Acc:92.53\n",
            "Epoch:31 --Progress(%):73.86-- Loss:0.22 -- Acc:92.49\n",
            "Epoch:31 --Progress(%):98.58-- Loss:0.22 -- Acc:92.37\n",
            "Epoch:31 --Val Loss:0.43 -- Acc:86.12\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 32\n",
            "Epoch:32 --Progress(%):24.43-- Loss:0.20 -- Acc:93.06\n",
            "Epoch:32 --Progress(%):49.15-- Loss:0.21 -- Acc:92.60\n",
            "Epoch:32 --Progress(%):73.86-- Loss:0.22 -- Acc:92.51\n",
            "Epoch:32 --Progress(%):98.58-- Loss:0.22 -- Acc:92.37\n",
            "Epoch:32 --Val Loss:0.50 -- Acc:84.44\n",
            "\n",
            "Epoch: 33\n",
            "Epoch:33 --Progress(%):24.43-- Loss:0.20 -- Acc:93.15\n",
            "Epoch:33 --Progress(%):49.15-- Loss:0.21 -- Acc:92.96\n",
            "Epoch:33 --Progress(%):73.86-- Loss:0.21 -- Acc:92.83\n",
            "Epoch:33 --Progress(%):98.58-- Loss:0.22 -- Acc:92.50\n",
            "Epoch:33 --Val Loss:0.50 -- Acc:84.32\n",
            "\n",
            "Epoch: 34\n",
            "Epoch:34 --Progress(%):24.43-- Loss:0.20 -- Acc:93.49\n",
            "Epoch:34 --Progress(%):49.15-- Loss:0.20 -- Acc:93.14\n",
            "Epoch:34 --Progress(%):73.86-- Loss:0.21 -- Acc:92.98\n",
            "Epoch:34 --Progress(%):98.58-- Loss:0.21 -- Acc:92.80\n",
            "Epoch:34 --Val Loss:0.45 -- Acc:85.66\n",
            "\n",
            "Epoch: 35\n",
            "Epoch:35 --Progress(%):24.43-- Loss:0.19 -- Acc:93.64\n",
            "Epoch:35 --Progress(%):49.15-- Loss:0.20 -- Acc:93.58\n",
            "Epoch:35 --Progress(%):73.86-- Loss:0.20 -- Acc:93.28\n",
            "Epoch:35 --Progress(%):98.58-- Loss:0.21 -- Acc:93.04\n",
            "Epoch:35 --Val Loss:0.53 -- Acc:83.34\n",
            "\n",
            "Epoch: 36\n",
            "Epoch:36 --Progress(%):24.43-- Loss:0.19 -- Acc:93.61\n",
            "Epoch:36 --Progress(%):49.15-- Loss:0.19 -- Acc:93.53\n",
            "Epoch:36 --Progress(%):73.86-- Loss:0.19 -- Acc:93.38\n",
            "Epoch:36 --Progress(%):98.58-- Loss:0.20 -- Acc:92.93\n",
            "Epoch:36 --Val Loss:0.46 -- Acc:85.14\n",
            "\n",
            "Epoch: 37\n",
            "Epoch:37 --Progress(%):24.43-- Loss:0.18 -- Acc:93.85\n",
            "Epoch:37 --Progress(%):49.15-- Loss:0.19 -- Acc:93.39\n",
            "Epoch:37 --Progress(%):73.86-- Loss:0.20 -- Acc:93.26\n",
            "Epoch:37 --Progress(%):98.58-- Loss:0.20 -- Acc:93.21\n",
            "Epoch:37 --Val Loss:0.51 -- Acc:85.24\n",
            "\n",
            "Epoch: 38\n",
            "Epoch:38 --Progress(%):24.43-- Loss:0.17 -- Acc:94.22\n",
            "Epoch:38 --Progress(%):49.15-- Loss:0.17 -- Acc:94.10\n",
            "Epoch:38 --Progress(%):73.86-- Loss:0.18 -- Acc:93.82\n",
            "Epoch:38 --Progress(%):98.58-- Loss:0.19 -- Acc:93.40\n",
            "Epoch:38 --Val Loss:0.54 -- Acc:83.06\n",
            "\n",
            "Epoch: 39\n",
            "Epoch:39 --Progress(%):24.43-- Loss:0.17 -- Acc:94.21\n",
            "Epoch:39 --Progress(%):49.15-- Loss:0.18 -- Acc:93.86\n",
            "Epoch:39 --Progress(%):73.86-- Loss:0.19 -- Acc:93.60\n",
            "Epoch:39 --Progress(%):98.58-- Loss:0.19 -- Acc:93.54\n",
            "Epoch:39 --Val Loss:0.47 -- Acc:85.26\n",
            "\n",
            "Epoch: 40\n",
            "Epoch:40 --Progress(%):24.43-- Loss:0.17 -- Acc:93.99\n",
            "Epoch:40 --Progress(%):49.15-- Loss:0.17 -- Acc:94.02\n",
            "Epoch:40 --Progress(%):73.86-- Loss:0.18 -- Acc:93.89\n",
            "Epoch:40 --Progress(%):98.58-- Loss:0.18 -- Acc:93.71\n",
            "Epoch:40 --Val Loss:0.46 -- Acc:85.58\n",
            "\n",
            "Epoch: 41\n",
            "Epoch:41 --Progress(%):24.43-- Loss:0.16 -- Acc:94.41\n",
            "Epoch:41 --Progress(%):49.15-- Loss:0.17 -- Acc:94.07\n",
            "Epoch:41 --Progress(%):73.86-- Loss:0.17 -- Acc:94.00\n",
            "Epoch:41 --Progress(%):98.58-- Loss:0.18 -- Acc:93.73\n",
            "Epoch:41 --Val Loss:0.53 -- Acc:84.22\n",
            "\n",
            "Epoch: 42\n",
            "Epoch:42 --Progress(%):24.43-- Loss:0.17 -- Acc:94.30\n",
            "Epoch:42 --Progress(%):49.15-- Loss:0.17 -- Acc:94.35\n",
            "Epoch:42 --Progress(%):73.86-- Loss:0.17 -- Acc:94.19\n",
            "Epoch:42 --Progress(%):98.58-- Loss:0.18 -- Acc:93.95\n",
            "Epoch:42 --Val Loss:0.39 -- Acc:87.56\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 43\n",
            "Epoch:43 --Progress(%):24.43-- Loss:0.16 -- Acc:94.75\n",
            "Epoch:43 --Progress(%):49.15-- Loss:0.16 -- Acc:94.61\n",
            "Epoch:43 --Progress(%):73.86-- Loss:0.17 -- Acc:94.24\n",
            "Epoch:43 --Progress(%):98.58-- Loss:0.18 -- Acc:94.04\n",
            "Epoch:43 --Val Loss:0.43 -- Acc:85.76\n",
            "\n",
            "Epoch: 44\n",
            "Epoch:44 --Progress(%):24.43-- Loss:0.16 -- Acc:94.72\n",
            "Epoch:44 --Progress(%):49.15-- Loss:0.16 -- Acc:94.72\n",
            "Epoch:44 --Progress(%):73.86-- Loss:0.16 -- Acc:94.53\n",
            "Epoch:44 --Progress(%):98.58-- Loss:0.17 -- Acc:94.31\n",
            "Epoch:44 --Val Loss:0.39 -- Acc:87.08\n",
            "\n",
            "Epoch: 45\n",
            "Epoch:45 --Progress(%):24.43-- Loss:0.16 -- Acc:94.73\n",
            "Epoch:45 --Progress(%):49.15-- Loss:0.16 -- Acc:94.57\n",
            "Epoch:45 --Progress(%):73.86-- Loss:0.17 -- Acc:94.40\n",
            "Epoch:45 --Progress(%):98.58-- Loss:0.17 -- Acc:94.31\n",
            "Epoch:45 --Val Loss:0.43 -- Acc:86.34\n",
            "\n",
            "Epoch: 46\n",
            "Epoch:46 --Progress(%):24.43-- Loss:0.15 -- Acc:94.87\n",
            "Epoch:46 --Progress(%):49.15-- Loss:0.15 -- Acc:94.72\n",
            "Epoch:46 --Progress(%):73.86-- Loss:0.16 -- Acc:94.59\n",
            "Epoch:46 --Progress(%):98.58-- Loss:0.16 -- Acc:94.46\n",
            "Epoch:46 --Val Loss:0.47 -- Acc:84.84\n",
            "\n",
            "Epoch: 47\n",
            "Epoch:47 --Progress(%):24.43-- Loss:0.15 -- Acc:95.02\n",
            "Epoch:47 --Progress(%):49.15-- Loss:0.15 -- Acc:94.70\n",
            "Epoch:47 --Progress(%):73.86-- Loss:0.16 -- Acc:94.55\n",
            "Epoch:47 --Progress(%):98.58-- Loss:0.17 -- Acc:94.16\n",
            "Epoch:47 --Val Loss:0.44 -- Acc:86.24\n",
            "\n",
            "Epoch: 48\n",
            "Epoch:48 --Progress(%):24.43-- Loss:0.15 -- Acc:94.59\n",
            "Epoch:48 --Progress(%):49.15-- Loss:0.15 -- Acc:94.67\n",
            "Epoch:48 --Progress(%):73.86-- Loss:0.16 -- Acc:94.50\n",
            "Epoch:48 --Progress(%):98.58-- Loss:0.16 -- Acc:94.47\n",
            "Epoch:48 --Val Loss:0.50 -- Acc:84.90\n",
            "\n",
            "Epoch: 49\n",
            "Epoch:49 --Progress(%):24.43-- Loss:0.15 -- Acc:95.27\n",
            "Epoch:49 --Progress(%):49.15-- Loss:0.15 -- Acc:94.99\n",
            "Epoch:49 --Progress(%):73.86-- Loss:0.15 -- Acc:94.81\n",
            "Epoch:49 --Progress(%):98.58-- Loss:0.16 -- Acc:94.57\n",
            "Epoch:49 --Val Loss:0.48 -- Acc:85.50\n",
            "\n",
            "Epoch: 50\n",
            "Epoch:50 --Progress(%):24.43-- Loss:0.14 -- Acc:95.17\n",
            "Epoch:50 --Progress(%):49.15-- Loss:0.14 -- Acc:95.19\n",
            "Epoch:50 --Progress(%):73.86-- Loss:0.15 -- Acc:94.87\n",
            "Epoch:50 --Progress(%):98.58-- Loss:0.15 -- Acc:94.71\n",
            "Epoch:50 --Val Loss:0.40 -- Acc:86.98\n",
            "\n",
            "Epoch: 51\n",
            "Epoch:51 --Progress(%):24.43-- Loss:0.14 -- Acc:95.40\n",
            "Epoch:51 --Progress(%):49.15-- Loss:0.14 -- Acc:95.34\n",
            "Epoch:51 --Progress(%):73.86-- Loss:0.15 -- Acc:95.10\n",
            "Epoch:51 --Progress(%):98.58-- Loss:0.15 -- Acc:94.89\n",
            "Epoch:51 --Val Loss:0.42 -- Acc:86.42\n",
            "\n",
            "Epoch: 52\n",
            "Epoch:52 --Progress(%):24.43-- Loss:0.14 -- Acc:95.11\n",
            "Epoch:52 --Progress(%):49.15-- Loss:0.14 -- Acc:95.15\n",
            "Epoch:52 --Progress(%):73.86-- Loss:0.15 -- Acc:95.09\n",
            "Epoch:52 --Progress(%):98.58-- Loss:0.15 -- Acc:94.97\n",
            "Epoch:52 --Val Loss:0.45 -- Acc:86.50\n",
            "\n",
            "Epoch: 53\n",
            "Epoch:53 --Progress(%):24.43-- Loss:0.13 -- Acc:95.52\n",
            "Epoch:53 --Progress(%):49.15-- Loss:0.14 -- Acc:95.25\n",
            "Epoch:53 --Progress(%):73.86-- Loss:0.15 -- Acc:95.06\n",
            "Epoch:53 --Progress(%):98.58-- Loss:0.15 -- Acc:94.95\n",
            "Epoch:53 --Val Loss:0.54 -- Acc:85.04\n",
            "\n",
            "Epoch: 54\n",
            "Epoch:54 --Progress(%):24.43-- Loss:0.14 -- Acc:95.02\n",
            "Epoch:54 --Progress(%):49.15-- Loss:0.14 -- Acc:95.18\n",
            "Epoch:54 --Progress(%):73.86-- Loss:0.14 -- Acc:95.18\n",
            "Epoch:54 --Progress(%):98.58-- Loss:0.14 -- Acc:95.09\n",
            "Epoch:54 --Val Loss:0.43 -- Acc:85.62\n",
            "\n",
            "Epoch: 55\n",
            "Epoch:55 --Progress(%):24.43-- Loss:0.12 -- Acc:96.02\n",
            "Epoch:55 --Progress(%):49.15-- Loss:0.13 -- Acc:95.70\n",
            "Epoch:55 --Progress(%):73.86-- Loss:0.13 -- Acc:95.70\n",
            "Epoch:55 --Progress(%):98.58-- Loss:0.13 -- Acc:95.56\n",
            "Epoch:55 --Val Loss:0.44 -- Acc:86.52\n",
            "\n",
            "Epoch: 56\n",
            "Epoch:56 --Progress(%):24.43-- Loss:0.12 -- Acc:96.22\n",
            "Epoch:56 --Progress(%):49.15-- Loss:0.13 -- Acc:95.62\n",
            "Epoch:56 --Progress(%):73.86-- Loss:0.14 -- Acc:95.32\n",
            "Epoch:56 --Progress(%):98.58-- Loss:0.14 -- Acc:95.16\n",
            "Epoch:56 --Val Loss:0.43 -- Acc:87.06\n",
            "\n",
            "Epoch: 57\n",
            "Epoch:57 --Progress(%):24.43-- Loss:0.12 -- Acc:96.17\n",
            "Epoch:57 --Progress(%):49.15-- Loss:0.12 -- Acc:96.08\n",
            "Epoch:57 --Progress(%):73.86-- Loss:0.13 -- Acc:95.73\n",
            "Epoch:57 --Progress(%):98.58-- Loss:0.13 -- Acc:95.55\n",
            "Epoch:57 --Val Loss:0.44 -- Acc:86.74\n",
            "\n",
            "Epoch: 58\n",
            "Epoch:58 --Progress(%):24.43-- Loss:0.12 -- Acc:96.15\n",
            "Epoch:58 --Progress(%):49.15-- Loss:0.12 -- Acc:96.15\n",
            "Epoch:58 --Progress(%):73.86-- Loss:0.12 -- Acc:95.90\n",
            "Epoch:58 --Progress(%):98.58-- Loss:0.13 -- Acc:95.77\n",
            "Epoch:58 --Val Loss:0.55 -- Acc:84.92\n",
            "\n",
            "Epoch: 59\n",
            "Epoch:59 --Progress(%):24.43-- Loss:0.12 -- Acc:96.04\n",
            "Epoch:59 --Progress(%):49.15-- Loss:0.13 -- Acc:95.86\n",
            "Epoch:59 --Progress(%):73.86-- Loss:0.13 -- Acc:95.81\n",
            "Epoch:59 --Progress(%):98.58-- Loss:0.13 -- Acc:95.75\n",
            "Epoch:59 --Val Loss:0.48 -- Acc:85.62\n",
            "\n",
            "Epoch: 60\n",
            "Epoch:60 --Progress(%):24.43-- Loss:0.12 -- Acc:96.08\n",
            "Epoch:60 --Progress(%):49.15-- Loss:0.12 -- Acc:95.91\n",
            "Epoch:60 --Progress(%):73.86-- Loss:0.13 -- Acc:95.57\n",
            "Epoch:60 --Progress(%):98.58-- Loss:0.13 -- Acc:95.44\n",
            "Epoch:60 --Val Loss:0.46 -- Acc:86.36\n",
            "\n",
            "Epoch: 61\n",
            "Epoch:61 --Progress(%):24.43-- Loss:0.11 -- Acc:96.24\n",
            "Epoch:61 --Progress(%):49.15-- Loss:0.11 -- Acc:96.22\n",
            "Epoch:61 --Progress(%):73.86-- Loss:0.12 -- Acc:95.94\n",
            "Epoch:61 --Progress(%):98.58-- Loss:0.13 -- Acc:95.69\n",
            "Epoch:61 --Val Loss:0.51 -- Acc:84.46\n",
            "\n",
            "Epoch: 62\n",
            "Epoch:62 --Progress(%):24.43-- Loss:0.11 -- Acc:96.37\n",
            "Epoch:62 --Progress(%):49.15-- Loss:0.11 -- Acc:96.25\n",
            "Epoch:62 --Progress(%):73.86-- Loss:0.12 -- Acc:96.04\n",
            "Epoch:62 --Progress(%):98.58-- Loss:0.12 -- Acc:95.88\n",
            "Epoch:62 --Val Loss:0.44 -- Acc:86.48\n",
            "\n",
            "Epoch: 63\n",
            "Epoch:63 --Progress(%):24.43-- Loss:0.11 -- Acc:96.31\n",
            "Epoch:63 --Progress(%):49.15-- Loss:0.10 -- Acc:96.57\n",
            "Epoch:63 --Progress(%):73.86-- Loss:0.11 -- Acc:96.20\n",
            "Epoch:63 --Progress(%):98.58-- Loss:0.12 -- Acc:95.99\n",
            "Epoch:63 --Val Loss:0.45 -- Acc:87.02\n",
            "\n",
            "Epoch: 64\n",
            "Epoch:64 --Progress(%):24.43-- Loss:0.11 -- Acc:96.48\n",
            "Epoch:64 --Progress(%):49.15-- Loss:0.11 -- Acc:96.33\n",
            "Epoch:64 --Progress(%):73.86-- Loss:0.11 -- Acc:96.12\n",
            "Epoch:64 --Progress(%):98.58-- Loss:0.12 -- Acc:95.97\n",
            "Epoch:64 --Val Loss:0.44 -- Acc:86.94\n",
            "\n",
            "Epoch: 65\n",
            "Epoch:65 --Progress(%):24.43-- Loss:0.11 -- Acc:96.21\n",
            "Epoch:65 --Progress(%):49.15-- Loss:0.11 -- Acc:96.22\n",
            "Epoch:65 --Progress(%):73.86-- Loss:0.11 -- Acc:96.16\n",
            "Epoch:65 --Progress(%):98.58-- Loss:0.12 -- Acc:96.05\n",
            "Epoch:65 --Val Loss:0.42 -- Acc:87.02\n",
            "\n",
            "Epoch: 66\n",
            "Epoch:66 --Progress(%):24.43-- Loss:0.10 -- Acc:96.52\n",
            "Epoch:66 --Progress(%):49.15-- Loss:0.10 -- Acc:96.56\n",
            "Epoch:66 --Progress(%):73.86-- Loss:0.11 -- Acc:96.42\n",
            "Epoch:66 --Progress(%):98.58-- Loss:0.11 -- Acc:96.34\n",
            "Epoch:66 --Val Loss:0.40 -- Acc:87.18\n",
            "\n",
            "Epoch: 67\n",
            "Epoch:67 --Progress(%):24.43-- Loss:0.09 -- Acc:96.93\n",
            "Epoch:67 --Progress(%):49.15-- Loss:0.10 -- Acc:96.50\n",
            "Epoch:67 --Progress(%):73.86-- Loss:0.11 -- Acc:96.26\n",
            "Epoch:67 --Progress(%):98.58-- Loss:0.11 -- Acc:96.17\n",
            "Epoch:67 --Val Loss:0.47 -- Acc:85.88\n",
            "\n",
            "Epoch: 68\n",
            "Epoch:68 --Progress(%):24.43-- Loss:0.11 -- Acc:96.50\n",
            "Epoch:68 --Progress(%):49.15-- Loss:0.11 -- Acc:96.37\n",
            "Epoch:68 --Progress(%):73.86-- Loss:0.11 -- Acc:96.19\n",
            "Epoch:68 --Progress(%):98.58-- Loss:0.11 -- Acc:96.17\n",
            "Epoch:68 --Val Loss:0.42 -- Acc:87.30\n",
            "\n",
            "Epoch: 69\n",
            "Epoch:69 --Progress(%):24.43-- Loss:0.10 -- Acc:96.78\n",
            "Epoch:69 --Progress(%):49.15-- Loss:0.10 -- Acc:96.81\n",
            "Epoch:69 --Progress(%):73.86-- Loss:0.10 -- Acc:96.57\n",
            "Epoch:69 --Progress(%):98.58-- Loss:0.11 -- Acc:96.41\n",
            "Epoch:69 --Val Loss:0.43 -- Acc:87.24\n",
            "\n",
            "Epoch: 70\n",
            "Epoch:70 --Progress(%):24.43-- Loss:0.10 -- Acc:96.52\n",
            "Epoch:70 --Progress(%):49.15-- Loss:0.11 -- Acc:96.40\n",
            "Epoch:70 --Progress(%):73.86-- Loss:0.11 -- Acc:96.36\n",
            "Epoch:70 --Progress(%):98.58-- Loss:0.11 -- Acc:96.25\n",
            "Epoch:70 --Val Loss:0.42 -- Acc:87.36\n",
            "\n",
            "Epoch: 71\n",
            "Epoch:71 --Progress(%):24.43-- Loss:0.10 -- Acc:96.61\n",
            "Epoch:71 --Progress(%):49.15-- Loss:0.10 -- Acc:96.79\n",
            "Epoch:71 --Progress(%):73.86-- Loss:0.10 -- Acc:96.64\n",
            "Epoch:71 --Progress(%):98.58-- Loss:0.11 -- Acc:96.45\n",
            "Epoch:71 --Val Loss:0.50 -- Acc:85.64\n",
            "\n",
            "Epoch: 72\n",
            "Epoch:72 --Progress(%):24.43-- Loss:0.10 -- Acc:96.50\n",
            "Epoch:72 --Progress(%):49.15-- Loss:0.10 -- Acc:96.63\n",
            "Epoch:72 --Progress(%):73.86-- Loss:0.11 -- Acc:96.52\n",
            "Epoch:72 --Progress(%):98.58-- Loss:0.11 -- Acc:96.44\n",
            "Epoch:72 --Val Loss:0.39 -- Acc:87.88\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 73\n",
            "Epoch:73 --Progress(%):24.43-- Loss:0.09 -- Acc:97.03\n",
            "Epoch:73 --Progress(%):49.15-- Loss:0.10 -- Acc:96.79\n",
            "Epoch:73 --Progress(%):73.86-- Loss:0.10 -- Acc:96.64\n",
            "Epoch:73 --Progress(%):98.58-- Loss:0.10 -- Acc:96.43\n",
            "Epoch:73 --Val Loss:0.44 -- Acc:86.92\n",
            "\n",
            "Epoch: 74\n",
            "Epoch:74 --Progress(%):24.43-- Loss:0.10 -- Acc:96.50\n",
            "Epoch:74 --Progress(%):49.15-- Loss:0.10 -- Acc:96.70\n",
            "Epoch:74 --Progress(%):73.86-- Loss:0.10 -- Acc:96.77\n",
            "Epoch:74 --Progress(%):98.58-- Loss:0.10 -- Acc:96.62\n",
            "Epoch:74 --Val Loss:0.41 -- Acc:87.94\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 75\n",
            "Epoch:75 --Progress(%):24.43-- Loss:0.09 -- Acc:97.14\n",
            "Epoch:75 --Progress(%):49.15-- Loss:0.09 -- Acc:97.14\n",
            "Epoch:75 --Progress(%):73.86-- Loss:0.09 -- Acc:97.12\n",
            "Epoch:75 --Progress(%):98.58-- Loss:0.10 -- Acc:96.86\n",
            "Epoch:75 --Val Loss:0.44 -- Acc:87.22\n",
            "\n",
            "Epoch: 76\n",
            "Epoch:76 --Progress(%):24.43-- Loss:0.09 -- Acc:96.92\n",
            "Epoch:76 --Progress(%):49.15-- Loss:0.10 -- Acc:96.69\n",
            "Epoch:76 --Progress(%):73.86-- Loss:0.10 -- Acc:96.67\n",
            "Epoch:76 --Progress(%):98.58-- Loss:0.10 -- Acc:96.68\n",
            "Epoch:76 --Val Loss:0.44 -- Acc:87.50\n",
            "\n",
            "Epoch: 77\n",
            "Epoch:77 --Progress(%):24.43-- Loss:0.09 -- Acc:97.15\n",
            "Epoch:77 --Progress(%):49.15-- Loss:0.10 -- Acc:96.88\n",
            "Epoch:77 --Progress(%):73.86-- Loss:0.10 -- Acc:96.81\n",
            "Epoch:77 --Progress(%):98.58-- Loss:0.10 -- Acc:96.76\n",
            "Epoch:77 --Val Loss:0.56 -- Acc:85.38\n",
            "\n",
            "Epoch: 78\n",
            "Epoch:78 --Progress(%):24.43-- Loss:0.08 -- Acc:97.50\n",
            "Epoch:78 --Progress(%):49.15-- Loss:0.08 -- Acc:97.42\n",
            "Epoch:78 --Progress(%):73.86-- Loss:0.08 -- Acc:97.26\n",
            "Epoch:78 --Progress(%):98.58-- Loss:0.09 -- Acc:97.14\n",
            "Epoch:78 --Val Loss:0.45 -- Acc:86.50\n",
            "\n",
            "Epoch: 79\n",
            "Epoch:79 --Progress(%):24.43-- Loss:0.08 -- Acc:97.34\n",
            "Epoch:79 --Progress(%):49.15-- Loss:0.09 -- Acc:97.17\n",
            "Epoch:79 --Progress(%):73.86-- Loss:0.09 -- Acc:97.09\n",
            "Epoch:79 --Progress(%):98.58-- Loss:0.09 -- Acc:96.93\n",
            "Epoch:79 --Val Loss:0.41 -- Acc:87.68\n",
            "\n",
            "Epoch: 80\n",
            "Epoch:80 --Progress(%):24.43-- Loss:0.07 -- Acc:97.93\n",
            "Epoch:80 --Progress(%):49.15-- Loss:0.07 -- Acc:97.69\n",
            "Epoch:80 --Progress(%):73.86-- Loss:0.08 -- Acc:97.42\n",
            "Epoch:80 --Progress(%):98.58-- Loss:0.08 -- Acc:97.23\n",
            "Epoch:80 --Val Loss:0.43 -- Acc:87.64\n",
            "\n",
            "Epoch: 81\n",
            "Epoch:81 --Progress(%):24.43-- Loss:0.08 -- Acc:97.27\n",
            "Epoch:81 --Progress(%):49.15-- Loss:0.08 -- Acc:97.39\n",
            "Epoch:81 --Progress(%):73.86-- Loss:0.08 -- Acc:97.29\n",
            "Epoch:81 --Progress(%):98.58-- Loss:0.09 -- Acc:97.03\n",
            "Epoch:81 --Val Loss:0.55 -- Acc:85.40\n",
            "\n",
            "Epoch: 82\n",
            "Epoch:82 --Progress(%):24.43-- Loss:0.09 -- Acc:97.25\n",
            "Epoch:82 --Progress(%):49.15-- Loss:0.08 -- Acc:97.52\n",
            "Epoch:82 --Progress(%):73.86-- Loss:0.08 -- Acc:97.50\n",
            "Epoch:82 --Progress(%):98.58-- Loss:0.08 -- Acc:97.44\n",
            "Epoch:82 --Val Loss:0.42 -- Acc:87.70\n",
            "\n",
            "Epoch: 83\n",
            "Epoch:83 --Progress(%):24.43-- Loss:0.07 -- Acc:97.76\n",
            "Epoch:83 --Progress(%):49.15-- Loss:0.07 -- Acc:97.62\n",
            "Epoch:83 --Progress(%):73.86-- Loss:0.08 -- Acc:97.48\n",
            "Epoch:83 --Progress(%):98.58-- Loss:0.08 -- Acc:97.28\n",
            "Epoch:83 --Val Loss:0.42 -- Acc:87.60\n",
            "\n",
            "Epoch: 84\n",
            "Epoch:84 --Progress(%):24.43-- Loss:0.08 -- Acc:97.38\n",
            "Epoch:84 --Progress(%):49.15-- Loss:0.08 -- Acc:97.26\n",
            "Epoch:84 --Progress(%):73.86-- Loss:0.08 -- Acc:97.17\n",
            "Epoch:84 --Progress(%):98.58-- Loss:0.09 -- Acc:97.06\n",
            "Epoch:84 --Val Loss:0.42 -- Acc:87.48\n",
            "\n",
            "Epoch: 85\n",
            "Epoch:85 --Progress(%):24.43-- Loss:0.08 -- Acc:97.51\n",
            "Epoch:85 --Progress(%):49.15-- Loss:0.07 -- Acc:97.57\n",
            "Epoch:85 --Progress(%):73.86-- Loss:0.08 -- Acc:97.51\n",
            "Epoch:85 --Progress(%):98.58-- Loss:0.08 -- Acc:97.46\n",
            "Epoch:85 --Val Loss:0.45 -- Acc:86.36\n",
            "\n",
            "Epoch: 86\n",
            "Epoch:86 --Progress(%):24.43-- Loss:0.08 -- Acc:97.40\n",
            "Epoch:86 --Progress(%):49.15-- Loss:0.08 -- Acc:97.54\n",
            "Epoch:86 --Progress(%):73.86-- Loss:0.08 -- Acc:97.42\n",
            "Epoch:86 --Progress(%):98.58-- Loss:0.08 -- Acc:97.29\n",
            "Epoch:86 --Val Loss:0.48 -- Acc:86.54\n",
            "\n",
            "Epoch: 87\n",
            "Epoch:87 --Progress(%):24.43-- Loss:0.08 -- Acc:97.64\n",
            "Epoch:87 --Progress(%):49.15-- Loss:0.07 -- Acc:97.62\n",
            "Epoch:87 --Progress(%):73.86-- Loss:0.07 -- Acc:97.65\n",
            "Epoch:87 --Progress(%):98.58-- Loss:0.08 -- Acc:97.54\n",
            "Epoch:87 --Val Loss:0.47 -- Acc:86.44\n",
            "\n",
            "Epoch: 88\n",
            "Epoch:88 --Progress(%):24.43-- Loss:0.08 -- Acc:97.40\n",
            "Epoch:88 --Progress(%):49.15-- Loss:0.08 -- Acc:97.59\n",
            "Epoch:88 --Progress(%):73.86-- Loss:0.08 -- Acc:97.54\n",
            "Epoch:88 --Progress(%):98.58-- Loss:0.08 -- Acc:97.54\n",
            "Epoch:88 --Val Loss:0.44 -- Acc:87.76\n",
            "\n",
            "Epoch: 89\n",
            "Epoch:89 --Progress(%):24.43-- Loss:0.07 -- Acc:97.86\n",
            "Epoch:89 --Progress(%):49.15-- Loss:0.07 -- Acc:97.98\n",
            "Epoch:89 --Progress(%):73.86-- Loss:0.07 -- Acc:97.75\n",
            "Epoch:89 --Progress(%):98.58-- Loss:0.08 -- Acc:97.62\n",
            "Epoch:89 --Val Loss:0.44 -- Acc:87.60\n",
            "\n",
            "Epoch: 90\n",
            "Epoch:90 --Progress(%):24.43-- Loss:0.06 -- Acc:97.99\n",
            "Epoch:90 --Progress(%):49.15-- Loss:0.07 -- Acc:97.82\n",
            "Epoch:90 --Progress(%):73.86-- Loss:0.07 -- Acc:97.74\n",
            "Epoch:90 --Progress(%):98.58-- Loss:0.07 -- Acc:97.64\n",
            "Epoch:90 --Val Loss:0.51 -- Acc:86.38\n",
            "\n",
            "Epoch: 91\n",
            "Epoch:91 --Progress(%):24.43-- Loss:0.07 -- Acc:97.67\n",
            "Epoch:91 --Progress(%):49.15-- Loss:0.07 -- Acc:97.64\n",
            "Epoch:91 --Progress(%):73.86-- Loss:0.07 -- Acc:97.55\n",
            "Epoch:91 --Progress(%):98.58-- Loss:0.07 -- Acc:97.61\n",
            "Epoch:91 --Val Loss:0.38 -- Acc:88.42\n",
            "Saving the best model.\n",
            "\n",
            "Epoch: 92\n",
            "Epoch:92 --Progress(%):24.43-- Loss:0.06 -- Acc:98.28\n",
            "Epoch:92 --Progress(%):49.15-- Loss:0.06 -- Acc:98.11\n",
            "Epoch:92 --Progress(%):73.86-- Loss:0.06 -- Acc:97.99\n",
            "Epoch:92 --Progress(%):98.58-- Loss:0.07 -- Acc:97.89\n",
            "Epoch:92 --Val Loss:0.47 -- Acc:86.84\n",
            "\n",
            "Epoch: 93\n",
            "Epoch:93 --Progress(%):24.43-- Loss:0.06 -- Acc:98.14\n",
            "Epoch:93 --Progress(%):49.15-- Loss:0.06 -- Acc:98.08\n",
            "Epoch:93 --Progress(%):73.86-- Loss:0.06 -- Acc:98.09\n",
            "Epoch:93 --Progress(%):98.58-- Loss:0.06 -- Acc:98.05\n",
            "Epoch:93 --Val Loss:0.42 -- Acc:88.26\n",
            "\n",
            "Epoch: 94\n",
            "Epoch:94 --Progress(%):24.43-- Loss:0.07 -- Acc:97.78\n",
            "Epoch:94 --Progress(%):49.15-- Loss:0.07 -- Acc:97.82\n",
            "Epoch:94 --Progress(%):73.86-- Loss:0.07 -- Acc:97.71\n",
            "Epoch:94 --Progress(%):98.58-- Loss:0.07 -- Acc:97.73\n",
            "Epoch:94 --Val Loss:0.47 -- Acc:87.08\n",
            "\n",
            "Epoch: 95\n",
            "Epoch:95 --Progress(%):24.43-- Loss:0.06 -- Acc:98.09\n",
            "Epoch:95 --Progress(%):49.15-- Loss:0.06 -- Acc:98.15\n",
            "Epoch:95 --Progress(%):73.86-- Loss:0.06 -- Acc:98.01\n",
            "Epoch:95 --Progress(%):98.58-- Loss:0.07 -- Acc:97.88\n",
            "Epoch:95 --Val Loss:0.45 -- Acc:87.46\n",
            "\n",
            "Epoch: 96\n",
            "Epoch:96 --Progress(%):24.43-- Loss:0.06 -- Acc:98.16\n",
            "Epoch:96 --Progress(%):49.15-- Loss:0.06 -- Acc:98.27\n",
            "Epoch:96 --Progress(%):73.86-- Loss:0.06 -- Acc:98.24\n",
            "Epoch:96 --Progress(%):98.58-- Loss:0.06 -- Acc:98.15\n",
            "Epoch:96 --Val Loss:0.50 -- Acc:87.42\n",
            "\n",
            "Epoch: 97\n",
            "Epoch:97 --Progress(%):24.43-- Loss:0.07 -- Acc:97.88\n",
            "Epoch:97 --Progress(%):49.15-- Loss:0.06 -- Acc:97.97\n",
            "Epoch:97 --Progress(%):73.86-- Loss:0.07 -- Acc:97.89\n",
            "Epoch:97 --Progress(%):98.58-- Loss:0.07 -- Acc:97.87\n",
            "Epoch:97 --Val Loss:0.48 -- Acc:86.68\n",
            "\n",
            "Epoch: 98\n",
            "Epoch:98 --Progress(%):24.43-- Loss:0.06 -- Acc:98.28\n",
            "Epoch:98 --Progress(%):49.15-- Loss:0.06 -- Acc:98.08\n",
            "Epoch:98 --Progress(%):73.86-- Loss:0.06 -- Acc:98.13\n",
            "Epoch:98 --Progress(%):98.58-- Loss:0.06 -- Acc:98.14\n",
            "Epoch:98 --Val Loss:0.42 -- Acc:88.34\n",
            "\n",
            "Epoch: 99\n",
            "Epoch:99 --Progress(%):24.43-- Loss:0.05 -- Acc:98.32\n",
            "Epoch:99 --Progress(%):49.15-- Loss:0.06 -- Acc:98.30\n",
            "Epoch:99 --Progress(%):73.86-- Loss:0.06 -- Acc:98.16\n",
            "Epoch:99 --Progress(%):98.58-- Loss:0.06 -- Acc:98.08\n",
            "Epoch:99 --Val Loss:0.43 -- Acc:88.22\n",
            "***** Begin testing *****\n",
            "Epoch:99 --Test Loss:0.43 -- Acc:88.69\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(start_epoch, start_epoch+100):\n",
        "    train(epoch)\n",
        "    scheduler.step()\n",
        "    val(epoch)\n",
        "    \n",
        "test(epoch)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d47c406849d845d1b14a36c3431faad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4924cd9ce7045bd9377db91b5975171",
              "IPY_MODEL_e6887cbe5bb8469b843faacad8f14726",
              "IPY_MODEL_542cd4293ccb431d9e5714e1cf8e9f59"
            ],
            "layout": "IPY_MODEL_65da4998ce6e4acd950cd7540276f9d2"
          }
        },
        "e4924cd9ce7045bd9377db91b5975171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5589772f63404758bb514a1f455a2aaf",
            "placeholder": "​",
            "style": "IPY_MODEL_5f9a78aaa1be4a8da4b6014779da7ac8",
            "value": "100%"
          }
        },
        "e6887cbe5bb8469b843faacad8f14726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_938ad89668d042758513ca615f710668",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4110dffcb8be4d4e9393ca222bd903f5",
            "value": 170498071
          }
        },
        "542cd4293ccb431d9e5714e1cf8e9f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cabf17df33e491d961a89b752d5a7d5",
            "placeholder": "​",
            "style": "IPY_MODEL_2b8237af6f464b7dad2ab4959e8c70e4",
            "value": " 170498071/170498071 [00:05&lt;00:00, 33308540.13it/s]"
          }
        },
        "65da4998ce6e4acd950cd7540276f9d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5589772f63404758bb514a1f455a2aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f9a78aaa1be4a8da4b6014779da7ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "938ad89668d042758513ca615f710668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4110dffcb8be4d4e9393ca222bd903f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cabf17df33e491d961a89b752d5a7d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b8237af6f464b7dad2ab4959e8c70e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}